{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46d51f6",
   "metadata": {},
   "source": [
    "# PyTorch Pruning: _LeNet-5_ Conv Net\n",
    "\n",
    "Trained on MNIST dataset using __global unstructured absolute magnitude__ based pruning.\n",
    "\n",
    "[PyTorch Pruning Tutorial](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#serializing-a-pruned-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a434618",
   "metadata": {
    "id": "GLciw6z8BZbt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e685559",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16325d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dacd3165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Available device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079da160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d307b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d5efe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters-\n",
    "# input_size = 784    # 28 x 28, flattened to be 1-D tensor\n",
    "# hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.0012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6acc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset statistics:\n",
    "# mean = tensor([0.1307]) & std dev = tensor([0.3081])\n",
    "mean = np.array([0.1307])\n",
    "std_dev = np.array([0.3081])\n",
    "\n",
    "transforms_apply = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = mean, std = std_dev)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957b1357",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/arjun/Documents/Programs/Python_Codes/PyTorch_Resources/Good_Codes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d33e7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset): 60000 & len(test_dataset): 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset-\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "        root = './data', train = True,\n",
    "        transform = transforms_apply, download = True\n",
    "        )\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "        root = './data', train = False,\n",
    "        transform = transforms_apply\n",
    "        )\n",
    "\n",
    "\n",
    "print(f\"len(train_dataset): {len(train_dataset)} & len(test_dataset): {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18dd5973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_loader) = 1875 & len(test_loader) = 313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1875, 313)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataloader-\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset = train_dataset, batch_size = batch_size,\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        dataset = test_dataset, batch_size = batch_size,\n",
    "        shuffle = False\n",
    "        )\n",
    "\n",
    "print(f\"len(train_loader) = {len(train_loader)} & len(test_loader) = {len(test_loader)}\")\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708781e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0aaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fa85f05",
   "metadata": {
    "id": "yOsmjuGvBZbu"
   },
   "source": [
    "### Create a model:\n",
    "\n",
    "In this tutorial, we use the [LeNet CNN](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf) architecture from LeCun et al., 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a268ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    '''\n",
    "    Implements a variation of LeNet-5 CNN. It is LeNet-4.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = 1, out_channels = 6,\n",
    "            kernel_size = 3, padding = 1,\n",
    "            stride = 1\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels = 6, out_channels = 16,\n",
    "            kernel_size = 3, padding = 1,\n",
    "            stride = 1\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels = 16, out_channels = 120,\n",
    "            kernel_size = 3, padding = 1,\n",
    "            stride = 1\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size = 2, stride = 2\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        # self.fc1 = nn.Linear(in_features = 512, out_features = 256)\n",
    "        # self.fc2 = nn.Linear(in_features = 120, out_features = 84)\n",
    "        # self.op = nn.Linear(in_features = 84, out_features = 10)\n",
    "        self.op = nn.Linear(in_features = 1080, out_features = 10)\n",
    "        \n",
    "        self.weights_initialization()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        return self.op(x)\n",
    "    \n",
    "    \n",
    "    def shape_computation(self, x):\n",
    "        x = self.conv1(x)\n",
    "        print(f\"conv1.shape = {x.shape}\")\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        print(f\"pool.shape = {x.shape}\")\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        print(f\"conv2.shape = {x.shape}\")\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        print(f\"pool.shape = {x.shape}\")\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        print(f\"conv3.shape = {x.shape}\")\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        print(f\"pool.shape = {x.shape}\")\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        print(f\"flatten.shape = {x.shape}\")\n",
    "        \n",
    "        x = self.op(x)\n",
    "        print(f\"output.shape = {x.shape}\")\n",
    "        \n",
    "    \n",
    "    def weights_initialization(self):\n",
    "        '''\n",
    "        When we define all the modules such as the layers in '__init__()'\n",
    "        method above, these are all stored in 'self.modules()'.\n",
    "        We go through each module one by one. This is the entire network,\n",
    "        basically.\n",
    "        '''\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efc93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f954adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LeNet5().to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer-\n",
    "# loss = nn.CrossEntropyLoss()    # applies softmax for us\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e85ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22e71da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    \n",
    "    tot_params = 0\n",
    "    for layer_name, param in model.named_parameters():\n",
    "        # print(f\"{layer_name}.shape = {param.shape} has {torch.count_nonzero(param.data)} non-zero params\")\n",
    "        tot_params += torch.count_nonzero(param.data)\n",
    "    \n",
    "    return tot_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_params = count_params(model)\n",
    "print(f\"Unpruned LeNet-4 model has {orig_params} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0619f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e31b7543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.name: conv1.weight & param.shape = torch.Size([6, 1, 3, 3])\n",
      "layer.name: conv1.bias & param.shape = torch.Size([6])\n",
      "layer.name: conv2.weight & param.shape = torch.Size([16, 6, 3, 3])\n",
      "layer.name: conv2.bias & param.shape = torch.Size([16])\n",
      "layer.name: conv3.weight & param.shape = torch.Size([120, 16, 3, 3])\n",
      "layer.name: conv3.bias & param.shape = torch.Size([120])\n",
      "layer.name: op.weight & param.shape = torch.Size([10, 1080])\n",
      "layer.name: op.bias & param.shape = torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for layer, param in model.named_parameters():\n",
    "    print(f\"layer.name: {layer} & param.shape = {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f447a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d83f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8b20089",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c673f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader):\n",
    "    '''\n",
    "    Function to perform one epoch of training by using 'train_loader'.\n",
    "    Returns loss and number of correct predictions for this epoch.\n",
    "    '''\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "\n",
    "    for batch, (images, labels) in enumerate(train_loader):\n",
    "        # Reshape image and place it on GPU-\n",
    "        # images = images.reshape(-1, input_size).to(device)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device) \n",
    "        outputs = model(images)   # forward pass\n",
    "        J = loss(outputs, labels) # compute loss\n",
    "        optimizer.zero_grad()     # empty accumulated gradients\n",
    "        J.backward()              # perform backpropagation\n",
    "        optimizer.step()          # update parameters\n",
    "\n",
    "        # Compute model's performance statistics-\n",
    "        running_loss += J.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(predicted == labels.data)\n",
    "\n",
    "        '''\n",
    "        # Print information every 100 steps-\n",
    "        if (batch + 1) % 100 == 0:\n",
    "            print(f\"epoch {epoch + 1}/{num_epochs}, step {batch + 1}/{num_steps}, loss = {J.item():.4f}\")\n",
    "        '''\n",
    "\n",
    "    return running_loss, running_corrects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ddfb831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    running_loss_val = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "\n",
    "            # Place features (images) and targets (labels) to GPU-\n",
    "            # images = images.reshape(-1, input_size).to(device)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # print(f\"images.shape = {images.shape}, labels.shape = {labels.shape}\")\n",
    "\n",
    "            # Set model to evaluation mode-\n",
    "            model.eval()\n",
    "    \n",
    "            # Make predictions using trained model-\n",
    "            outputs = model(images)\n",
    "            _, y_pred = torch.max(outputs, 1)\n",
    "\n",
    "            # Compute validation loss-\n",
    "            J_val = loss(outputs, labels)\n",
    "\n",
    "            running_loss_val += J_val.item() * labels.size(0)\n",
    "    \n",
    "            # Total number of labels-\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Total number of correct predictions-\n",
    "            correct += (y_pred == labels).sum()\n",
    "\n",
    "    return (running_loss_val, correct, total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3728ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d23ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input parameters for Early Stopping in manual implementation-\n",
    "minimum_delta = 0.001\n",
    "patience = 5\n",
    "\n",
    "\n",
    "# Initialize parameters for Early Stopping manual implementation-\n",
    "best_val_loss = 100\n",
    "loc_patience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c048c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python3 lists to store model training metrics-\n",
    "training_acc = []\n",
    "validation_acc = []\n",
    "training_loss = []\n",
    "validation_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda02a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7106cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop-\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    \n",
    "    if loc_patience >= patience:\n",
    "        print(\"\\n'EarlyStopping' called!\\n\")\n",
    "        break\n",
    "\n",
    "    running_loss, running_corrects = train_model(model, train_loader)\n",
    "  \n",
    "    # Compute training loss and accuracy for one epoch-\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "    # epoch_acc = 100 * running_corrects / len(trainset)\n",
    "    # print(f\"\\nepoch: {epoch + 1} training loss = {epoch_loss:.4f}, training accuracy = {epoch_acc * 100:.2f}%\\n\")\n",
    "\n",
    "    running_loss_val, correct, total = test_model(model, test_loader)\n",
    "\n",
    "    # Compute validation loss and accuracy-\n",
    "    epoch_val_loss = running_loss_val / len(test_dataset)\n",
    "    val_acc = 100 * (correct / total)\n",
    "    # print(f\"\\nepoch: {epoch + 1} training loss = {epoch_loss:.4f}, training accuracy = {epoch_acc * 100:.2f}%, val_loss = {epoch_val_loss:.4f} & val_accuracy = {val_acc:.2f}%\\n\")\n",
    "\n",
    "    print(f\"\\nepoch: {epoch + 1} training loss = {epoch_loss:.4f}, training accuracy = {epoch_acc * 100:.2f}%, val_loss = {epoch_val_loss:.4f} & val_accuracy = {val_acc:.2f}%\\n\")\n",
    "\n",
    "    # Code for manual Early Stopping:\n",
    "    # if np.abs(epoch_val_loss < best_val_loss) >= minimum_delta:\n",
    "    if (epoch_val_loss < best_val_loss) and np.abs(epoch_val_loss - best_val_loss) >= minimum_delta:\n",
    "        # print(f\"epoch_val_loss = {epoch_val_loss:.4f}, best_val_loss = {best_val_loss:.4f}\")\n",
    "        \n",
    "        # update 'best_val_loss' variable to lowest loss encountered so far-\n",
    "        best_val_loss = epoch_val_loss\n",
    "        \n",
    "        # reset 'loc_patience' variable-\n",
    "        loc_patience = 0\n",
    "        \n",
    "        print(f\"Saving model with lowest val_loss = {epoch_val_loss:.4f}\\n\")\n",
    "        \n",
    "        # Save trained model with validation accuracy-\n",
    "        # torch.save(model.state_dict, f\"LeNet-300-100_Trained_{val_acc}.pth\")\n",
    "        torch.save(model.state_dict(), \"LeNet-4_Trained.pth\")\n",
    "        \n",
    "    else:  # there is no improvement in monitored metric 'val_loss'\n",
    "        loc_patience += 1  # number of epochs without any improvement\n",
    "\n",
    "\n",
    "    training_acc.append(epoch_acc * 100)\n",
    "    validation_acc.append(val_acc)\n",
    "    training_loss.append(epoch_loss)\n",
    "    validation_loss.append(epoch_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8a960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f46372c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and load best weights-\n",
    "best_model = LeNet5().to(device = device)\n",
    "best_model.load_state_dict(torch.load(\"/home/arjun/Documents/Programs/Python_Codes/PyTorch_Resources/Good_Codes/Pruning_codes_and_resources/LeNet-4_Trained.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18ad4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer-\n",
    "loss = nn.CrossEntropyLoss()    # applies softmax for us\n",
    "optimizer = torch.optim.Adam(best_model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19a1a670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of non-zero parameter in unpruned LeNet-4 CNN = 29150\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of non-zero parameter in unpruned LeNet-4 CNN = {count_params(best_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de430842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b066f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45392b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trained LeNet-4 metrics on validation dataset:\n",
      "val_loss = 0.0247 & val_acc = 99.21%\n"
     ]
    }
   ],
   "source": [
    "# Compute 'best weights' metrics on validation dataset-\n",
    "running_loss_val, correct, total = test_model(best_model, test_loader)\n",
    "\n",
    "# Compute validation loss and accuracy-\n",
    "val_loss = running_loss_val / len(test_dataset)\n",
    "val_acc = 100 * (correct / total)\n",
    "\n",
    "print(\"Best trained LeNet-4 metrics on validation dataset:\")\n",
    "print(f\"val_loss = {val_loss:.4f} & val_acc = {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3408555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f10870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 3, 3])\n",
      "conv1.bias torch.Size([6])\n",
      "conv2.weight torch.Size([16, 6, 3, 3])\n",
      "conv2.bias torch.Size([16])\n",
      "conv3.weight torch.Size([120, 16, 3, 3])\n",
      "conv3.bias torch.Size([120])\n",
      "op.weight torch.Size([10, 1080])\n",
      "op.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for layer_name in best_model.state_dict().keys():\n",
    "    print(layer_name, best_model.state_dict()[layer_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "148655b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'conv3.weight', 'conv3.bias', 'op.weight', 'op.bias'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c8a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456d36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c2ea373",
   "metadata": {},
   "source": [
    "## Global pruning:\n",
    "\n",
    "A common and powerful technique is to prune the model all at once, by removing (for example) the lowest 20% of connections across the whole model, instead of removing the lowest 20% of connections in each layer. This is likely to result in different pruning percentages per layer. Letâ€™s see how to do that using global_unstructured from ``torch.nn.utils.prune``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a86c4b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprune.global_unstructured(\\n    parameters_to_prune,\\n    pruning_method = prune.L1Unstructured,\\n    amount = 0.2,\\n)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameters/layers to be pruned-\n",
    "parameters_to_prune = (\n",
    "    (best_model.conv1, 'weight'),\n",
    "    (best_model.conv2, 'weight'),\n",
    "    (best_model.conv3, 'weight'),\n",
    "    (best_model.op, 'weight')\n",
    ")\n",
    "\n",
    "'''\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method = prune.L1Unstructured,\n",
    "    amount = 0.2,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a761878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3e6df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sparsity(best_model):\n",
    "    conv1_sparsity = (torch.sum(best_model.conv1.weight == 0) / best_model.conv1.weight.nelement()) * 100\n",
    "    conv2_sparsity = (torch.sum(best_model.conv2.weight == 0) / best_model.conv2.weight.nelement()) * 100\n",
    "    conv3_sparsity = (torch.sum(best_model.conv3.weight == 0) / best_model.conv3.weight.nelement()) * 100\n",
    "    op_sparsity = (torch.sum(best_model.op.weight == 0) / best_model.op.weight.nelement()) * 100\n",
    "\n",
    "    # Compute global sparsity-\n",
    "    num = torch.sum(best_model.conv1.weight == 0) + torch.sum(best_model.conv2.weight == 0) + torch.sum(best_model.conv3.weight == 0) \\\n",
    "            + torch.sum(best_model.op.weight == 0)\n",
    "\n",
    "    denom = best_model.conv1.weight.nelement() + best_model.conv2.weight.nelement() + best_model.conv3.weight.nelement() \\\n",
    "            + best_model.op.weight.nelement()\n",
    "\n",
    "    global_sparsity = num / denom * 100\n",
    "\n",
    "    '''\n",
    "    print(f\"conv1.weight has {conv1_sparsity:.2f}% sparsity\")\n",
    "    print(f\"conv2.weight has {conv2_sparsity:.2f}% sparsity\")\n",
    "    print(f\"conv3.weight has {conv3_sparsity:.2f}% sparsity\")\n",
    "    print(f\"op.weight has {op_sparsity:.2f}% sparsity\")\n",
    "    '''\n",
    "    print(f\"LeNet-4 Global Sparsity = {global_sparsity:.2f}%\")\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb2e6f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-4 Global Sparsity = 0.00%\n"
     ]
    }
   ],
   "source": [
    "compute_sparsity(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c38da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e447f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method = prune.L1Unstructured,\n",
    "    amount = 0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "baa14db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-4 Global Sparsity = 52.00%\n"
     ]
    }
   ],
   "source": [
    "compute_sparsity(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d435b7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(29150)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5907e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa6193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c677c643",
   "metadata": {},
   "source": [
    "### Iterative Global Pruning algorithm:\n",
    "\n",
    "Take an already trained model and repear the following steps _x_ times-\n",
    "\n",
    "- prune p% of smallest magnitude weights in an __unstructured global manner__\n",
    "\n",
    "- fine-tune pruned model to recover performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5481da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input parameters for Early Stopping in manual implementation-\n",
    "minimum_delta = 0.001\n",
    "patience = 3\n",
    "\n",
    "\n",
    "# Initialize parameters for Early Stopping manual implementation-\n",
    "best_val_loss = 100\n",
    "loc_patience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e846d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Python3 lists to store model training metrics-\n",
    "training_acc = []\n",
    "validation_acc = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df0b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "798154b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global pruning rates-\n",
    "prune_rates_global = [0.2, 0.3, 0.4, 0.5, 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90eaebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for iter_prune_round in range(5):\n",
    "    print(prune_rates_global[iter_prune_round])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb18372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46a4bf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Iterative Global pruning round = 1 with global sparsity = 20.0%\n",
      "LeNet-4 Global Sparsity = 20.00%\n",
      "\n",
      "Fine-tuning pruned model to recover model's performance\n",
      "\n",
      "\n",
      "epoch: 1 training loss = 0.0088, training accuracy = 99.72%, val_loss = 0.0315 & val_accuracy = 99.09%\n",
      "\n",
      "Saving model with lowest val_loss = 0.0315 for iterative pruning round = 1\n",
      "\n",
      "\n",
      "epoch: 2 training loss = 0.0065, training accuracy = 99.77%, val_loss = 0.0350 & val_accuracy = 99.13%\n",
      "\n",
      "\n",
      "epoch: 3 training loss = 0.0058, training accuracy = 99.79%, val_loss = 0.0326 & val_accuracy = 99.26%\n",
      "\n",
      "\n",
      "epoch: 4 training loss = 0.0065, training accuracy = 99.78%, val_loss = 0.0366 & val_accuracy = 99.13%\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "\n",
      "\n",
      "Iterative Global pruning round = 2 with global sparsity = 30.0%\n",
      "LeNet-4 Global Sparsity = 44.00%\n",
      "\n",
      "Fine-tuning pruned model to recover model's performance\n",
      "\n",
      "\n",
      "epoch: 1 training loss = 0.0046, training accuracy = 99.83%, val_loss = 0.0326 & val_accuracy = 99.30%\n",
      "\n",
      "Saving model with lowest val_loss = 0.0326 for iterative pruning round = 2\n",
      "\n",
      "\n",
      "epoch: 2 training loss = 0.0023, training accuracy = 99.93%, val_loss = 0.0405 & val_accuracy = 99.23%\n",
      "\n",
      "\n",
      "epoch: 3 training loss = 0.0031, training accuracy = 99.90%, val_loss = 0.0472 & val_accuracy = 99.04%\n",
      "\n",
      "\n",
      "epoch: 4 training loss = 0.0028, training accuracy = 99.90%, val_loss = 0.0465 & val_accuracy = 99.14%\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "\n",
      "\n",
      "Iterative Global pruning round = 3 with global sparsity = 40.0%\n",
      "LeNet-4 Global Sparsity = 66.40%\n",
      "\n",
      "Fine-tuning pruned model to recover model's performance\n",
      "\n",
      "\n",
      "epoch: 1 training loss = 0.0122, training accuracy = 99.59%, val_loss = 0.0357 & val_accuracy = 99.13%\n",
      "\n",
      "Saving model with lowest val_loss = 0.0357 for iterative pruning round = 3\n",
      "\n",
      "\n",
      "epoch: 2 training loss = 0.0031, training accuracy = 99.91%, val_loss = 0.0383 & val_accuracy = 99.14%\n",
      "\n",
      "\n",
      "epoch: 3 training loss = 0.0017, training accuracy = 99.95%, val_loss = 0.0519 & val_accuracy = 99.07%\n",
      "\n",
      "\n",
      "epoch: 4 training loss = 0.0029, training accuracy = 99.89%, val_loss = 0.0550 & val_accuracy = 99.00%\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "\n",
      "\n",
      "Iterative Global pruning round = 4 with global sparsity = 50.0%\n",
      "LeNet-4 Global Sparsity = 83.20%\n",
      "\n",
      "Fine-tuning pruned model to recover model's performance\n",
      "\n",
      "\n",
      "epoch: 1 training loss = 0.0389, training accuracy = 98.67%, val_loss = 0.0433 & val_accuracy = 98.74%\n",
      "\n",
      "Saving model with lowest val_loss = 0.0433 for iterative pruning round = 4\n",
      "\n",
      "\n",
      "epoch: 2 training loss = 0.0181, training accuracy = 99.38%, val_loss = 0.0423 & val_accuracy = 98.77%\n",
      "\n",
      "Saving model with lowest val_loss = 0.0423 for iterative pruning round = 4\n",
      "\n",
      "\n",
      "epoch: 3 training loss = 0.0132, training accuracy = 99.54%, val_loss = 0.0458 & val_accuracy = 98.74%\n",
      "\n",
      "\n",
      "epoch: 4 training loss = 0.0100, training accuracy = 99.67%, val_loss = 0.0451 & val_accuracy = 98.78%\n",
      "\n",
      "\n",
      "epoch: 5 training loss = 0.0074, training accuracy = 99.74%, val_loss = 0.0527 & val_accuracy = 98.71%\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "\n",
      "\n",
      "Iterative Global pruning round = 5 with global sparsity = 60.0%\n",
      "LeNet-4 Global Sparsity = 93.28%\n",
      "\n",
      "Fine-tuning pruned model to recover model's performance\n",
      "\n",
      "\n",
      "epoch: 1 training loss = 0.2021, training accuracy = 93.51%, val_loss = 0.1308 & val_accuracy = 95.79%\n",
      "\n",
      "Saving model with lowest val_loss = 0.1308 for iterative pruning round = 5\n",
      "\n",
      "\n",
      "epoch: 2 training loss = 0.1133, training accuracy = 96.31%, val_loss = 0.1107 & val_accuracy = 96.54%\n",
      "\n",
      "Saving model with lowest val_loss = 0.1107 for iterative pruning round = 5\n",
      "\n",
      "\n",
      "epoch: 3 training loss = 0.0978, training accuracy = 96.85%, val_loss = 0.1019 & val_accuracy = 96.83%\n",
      "\n",
      "Saving model with lowest val_loss = 0.1019 for iterative pruning round = 5\n",
      "\n",
      "\n",
      "epoch: 4 training loss = 0.0891, training accuracy = 97.16%, val_loss = 0.0960 & val_accuracy = 97.00%\n",
      "\n",
      "Saving model with lowest val_loss = 0.0960 for iterative pruning round = 5\n",
      "\n",
      "\n",
      "epoch: 5 training loss = 0.0829, training accuracy = 97.32%, val_loss = 0.0908 & val_accuracy = 97.13%\n",
      "\n",
      "Saving model with lowest val_loss = 0.0908 for iterative pruning round = 5\n",
      "\n",
      "\n",
      "epoch: 6 training loss = 0.0789, training accuracy = 97.42%, val_loss = 0.0889 & val_accuracy = 97.14%\n",
      "\n",
      "Saving model with lowest val_loss = 0.0889 for iterative pruning round = 5\n",
      "\n",
      "\n",
      "epoch: 7 training loss = 0.0754, training accuracy = 97.58%, val_loss = 0.0832 & val_accuracy = 97.42%\n",
      "\n",
      "Saving model with lowest val_loss = 0.0832 for iterative pruning round = 5\n",
      "\n",
      "\n",
      "epoch: 8 training loss = 0.0726, training accuracy = 97.66%, val_loss = 0.0817 & val_accuracy = 97.31%\n",
      "\n",
      "Saving model with lowest val_loss = 0.0817 for iterative pruning round = 5\n",
      "\n",
      "\n",
      "epoch: 9 training loss = 0.0698, training accuracy = 97.74%, val_loss = 0.0820 & val_accuracy = 97.46%\n",
      "\n",
      "\n",
      "epoch: 10 training loss = 0.0680, training accuracy = 97.80%, val_loss = 0.0849 & val_accuracy = 97.32%\n",
      "\n",
      "\n",
      "epoch: 11 training loss = 0.0664, training accuracy = 97.84%, val_loss = 0.0808 & val_accuracy = 97.44%\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for iter_prune_round in range(5):\n",
    "    print(f\"\\n\\nIterative Global pruning round = {iter_prune_round + 1} with global sparsity = {prune_rates_global[iter_prune_round] * 100}%\")\n",
    "    \n",
    "    # Prune globally-\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method = prune.L1Unstructured,\n",
    "        amount = prune_rates_global[iter_prune_round]\n",
    "    )\n",
    "        \n",
    "    # Print current global sparsity level-\n",
    "    compute_sparsity(best_model)\n",
    "\n",
    "    \n",
    "    # Fine-training loop-\n",
    "    print(\"\\nFine-tuning pruned model to recover model's performance\\n\")\n",
    "    \n",
    "    # Initialize parameters for Early Stopping manual implementation-\n",
    "    best_val_loss = 100\n",
    "    loc_patience = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "    \n",
    "        if loc_patience >= patience:\n",
    "            print(\"\\n'EarlyStopping' called!\\n\")\n",
    "            break\n",
    "\n",
    "        running_loss, running_corrects = train_model(best_model, train_loader)\n",
    "  \n",
    "        # Compute training loss and accuracy for one epoch-\n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "    \n",
    "        running_loss_val, correct, total = test_model(best_model, test_loader)\n",
    "\n",
    "        # Compute validation loss and accuracy-\n",
    "        epoch_val_loss = running_loss_val / len(test_dataset)\n",
    "        val_acc = 100 * (correct / total)\n",
    "    \n",
    "        print(f\"\\nepoch: {epoch + 1} training loss = {epoch_loss:.4f}, training accuracy = {epoch_acc * 100:.2f}%, val_loss = {epoch_val_loss:.4f} & val_accuracy = {val_acc:.2f}%\\n\")\n",
    "\n",
    "        # Code for manual Early Stopping:\n",
    "        if (epoch_val_loss < best_val_loss) and np.abs(epoch_val_loss - best_val_loss) >= minimum_delta:\n",
    "        \n",
    "            # update 'best_val_loss' variable to lowest loss encountered so far-\n",
    "            best_val_loss = epoch_val_loss\n",
    "        \n",
    "            # reset 'loc_patience' variable-\n",
    "            loc_patience = 0\n",
    "        \n",
    "            print(f\"Saving model with lowest val_loss = {epoch_val_loss:.4f} for iterative pruning round = {iter_prune_round + 1}\\n\")\n",
    "        \n",
    "            # Save trained model with validation accuracy-\n",
    "            # torch.save(model.state_dict, f\"LeNet-300-100_Trained_{val_acc}.pth\")\n",
    "            torch.save(best_model.state_dict(), \"LeNet-4_Trained.pth\")\n",
    "        \n",
    "        else:  # there is no improvement in monitored metric 'val_loss'\n",
    "            loc_patience += 1  # number of epochs without any improvement\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f7ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca0071e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2519,  0.6400,  0.0337],\n",
       "        [ 0.3763,  0.5416, -0.1623],\n",
       "        [-0.0104, -0.2920, -0.4409]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original unpruned weights-\n",
    "best_model.state_dict()['conv1.weight_orig'][0, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1abcbb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pruned mask-\n",
    "best_model.state_dict()['conv1.weight_mask'][0, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91c1b651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, 0.6400, 0.0000],\n",
       "        [0.0000, 0.5416, -0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise multiplication between weights & masks-\n",
    "best_model.state_dict()['conv1.weight_orig'][0, 0, :, :] * best_model.state_dict()['conv1.weight_mask'][0, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84600990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4345e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, 0.6400, 0.0000],\n",
       "        [0.0000, 0.5416, -0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pruned weights-\n",
    "best_model.conv1.weight[0, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a62bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc2a4886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.bias', 'conv1.weight_orig', 'conv1.weight_mask', 'conv2.bias', 'conv2.weight_orig', 'conv2.weight_mask', 'conv3.bias', 'conv3.weight_orig', 'conv3.weight_mask', 'op.bias', 'op.weight_orig', 'op.weight_mask'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e64ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b0a7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a66b580c",
   "metadata": {},
   "source": [
    "### Remove pruning re-parametrization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08bbc5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1080, out_features=10, bias=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.remove(best_model.conv1, 'weight')\n",
    "prune.remove(best_model.conv2, 'weight')\n",
    "prune.remove(best_model.conv3, 'weight')\n",
    "prune.remove(best_model.op, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119c473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1ad3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(best_model.conv1.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "755bc5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer = conv1.weight has 75.93% sparsity\n",
      "layer = conv2.weight has 90.39% sparsity\n",
      "layer = conv3.weight has 94.13% sparsity\n",
      "layer = op.weight has 92.25% sparsity\n"
     ]
    }
   ],
   "source": [
    "for layer_name in best_model.state_dict().keys():\n",
    "    if 'bias' in layer_name:\n",
    "        continue\n",
    "    else:\n",
    "        loc_sparsity = (torch.sum(best_model.state_dict()[layer_name] == 0) / best_model.state_dict()[layer_name].nelement()) * 100\n",
    "        # print(f\"layer = {layer_name} has {best_model.state_dict()[layer_name].shape}\")\n",
    "        print(f\"layer = {layer_name} has {loc_sparsity:.2f}% sparsity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ccb65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc67a2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: conv1.bias has shape: torch.Size([6])\n",
      "layer: conv1.weight has shape: torch.Size([6, 1, 3, 3])\n",
      "layer: conv2.bias has shape: torch.Size([16])\n",
      "layer: conv2.weight has shape: torch.Size([16, 6, 3, 3])\n",
      "layer: conv3.bias has shape: torch.Size([120])\n",
      "layer: conv3.weight has shape: torch.Size([120, 16, 3, 3])\n",
      "layer: op.bias has shape: torch.Size([10])\n",
      "layer: op.weight has shape: torch.Size([10, 1080])\n"
     ]
    }
   ],
   "source": [
    "for layer_name, param in best_model.named_parameters():\n",
    "    print(f\"layer: {layer_name} has shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996d307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c59935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a7aaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
