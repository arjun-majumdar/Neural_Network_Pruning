{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "second-sunset",
   "metadata": {
    "id": "af7dfe97-8041-45d0-9af9-94e891c60717"
   },
   "source": [
    "# PyTorch Global, Unstructured, Absolute Magnitude & Iterative Pruning:\n",
    "\n",
    "Using _ResNet-50_ CNN trained from scratch on CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "physical-mailing",
   "metadata": {
    "id": "93d5a78d-c1cb-4922-a068-2f82d4657762"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-humor",
   "metadata": {
    "id": "9181199a-6b61-42e4-9630-809e814d9cd6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "north-reflection",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce5531ac-9882-4389-a268-6f59fc37b1f4",
    "outputId": "4e9dd6fd-ec6f-4ce8-ce79-24da53a15df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.8.1\n",
      "Torchvision Version: 0.9.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Torchvision Version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-lawyer",
   "metadata": {
    "id": "d82a94bf-4390-4402-98fc-b8f8e39537f0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "satellite-detail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER = PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collectible-latin",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c553ad2-a75a-4503-a368-b5e3ee848bb0",
    "outputId": "5c3b98d9-f2ba-45b3-d2af-2351e8f9b312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently available device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration-\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"currently available device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-tomorrow",
   "metadata": {
    "id": "5f41273e-83d9-4ecb-949d-dc552e256c98"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alternative-productivity",
   "metadata": {
    "id": "699d2c1c-059c-4d50-b6f9-a500f6a6c411"
   },
   "outputs": [],
   "source": [
    "# Define transformations for training and test sets-\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "      transforms.RandomCrop(32, padding = 4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "     ]\n",
    "     )\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "     ]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "miniature-arrangement",
   "metadata": {
    "id": "6452fe10-c517-4ef1-8f15-18d9e1e0ba96"
   },
   "outputs": [],
   "source": [
    "# Change to directory containing CIFAR10 dataset-\n",
    "# os.chdir(\"/home/arjun/Documents/Programs/Python_Codes/PyTorch_Resources/Good_Codes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mineral-helen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "fea7f1d561514a0da92664717b8515c6",
      "b1cac9f553064d35b254b81d890e52a3",
      "2099c8dece854e6e819550a228ee3cd7",
      "a36dbd2cb3924fecbbadf92c884898f7",
      "4cc0ee1a167a411684ee8baab0f59236",
      "f06268f3268b4bc99258902958afb3e8",
      "164f25694e0548c2ab4c689cd739f340",
      "bd4e2bb0a01e42c49833287b4f24d7e4"
     ]
    },
    "id": "552ac198-0383-4ac5-88aa-844ab9f3dab3",
    "outputId": "8f57f08b-7415-4d1c-95fb-15984f813a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load dataset-\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "        root = './data', train = True,\n",
    "        download = True, transform = transform_train\n",
    "        )\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "        root = './data', train = False,\n",
    "        download = True, transform = transform_test\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chubby-syria",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79d37aad-a4c8-4852-a0d8-d46484e437ad",
    "outputId": "1e223774-9000-43c0-d40e-5cf25f4c5a0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset) = 50000 & len(test_dataset) = 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(train_dataset) = {len(train_dataset)} & len(test_dataset) = {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "excess-particular",
   "metadata": {
    "id": "ad956a5b-cddc-4c57-b0ea-38d56997a222"
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "supposed-curtis",
   "metadata": {
    "id": "ffd8cbdc-919e-48de-883e-49e116a1faff"
   },
   "outputs": [],
   "source": [
    "# Create training and testing loaders-\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size = batch_size,\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size = batch_size,\n",
    "        shuffle = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "loved-default",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caf0903b-94a0-46ae-9e08-10518878e892",
    "outputId": "517189a8-f53f-4eb2-c8ad-65be34aa7421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_loader) = 391 & len(test_loader) = 79\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(train_loader) = {len(train_loader)} & len(test_loader) = {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sharp-neighbor",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd5694f9-f68b-4cff-bb1b-c41899f6cc82",
    "outputId": "01c72e0f-4fea-4237-e4a2-9c58295b773b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390.625, 78.125)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "len(train_dataset) / batch_size, len(test_dataset) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-switzerland",
   "metadata": {
    "id": "d27d93f4-73d8-4c92-af87-a1827b8d597e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-cover",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c981dc86-9f49-45f4-8527-23145c8788dd",
    "outputId": "8898cd80-f80d-4445-9573-2790b0db453e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape: torch.Size([128, 3, 32, 32]) & labels.shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Get some random training images-\n",
    "# some_img = iter(train_loader)\n",
    "# images, labels = some_img.next()\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# You get 32 images due to our specified batch size-\n",
    "print(f\"images.shape: {images.shape} & labels.shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-taylor",
   "metadata": {
    "id": "b339374b-0ba4-4007-b5a0-50c3a1ec48a9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-wichita",
   "metadata": {
    "id": "e191db83-dcf0-441e-b0a8-f4f7c209d067"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "front-discrimination",
   "metadata": {
    "id": "002a213d-0411-49b8-ad6c-9086cbb0a4a2"
   },
   "outputs": [],
   "source": [
    "# Initialize and load 'best' weights from before-\n",
    "trained_model = models.resnet50(pretrained = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "north-angel",
   "metadata": {
    "id": "c50c5dbe-9612-4e40-a027-8c3c31d49e99"
   },
   "outputs": [],
   "source": [
    "# Compute number of features for defining last linear/dense layer-\n",
    "num_ftrs = trained_model.fc.in_features\n",
    "\n",
    "# Define last dense layer-\n",
    "trained_model.fc = nn.Linear(in_features = num_ftrs, out_features = 10)\n",
    "\n",
    "# Change first conv layer of ResNet-50:\n",
    "trained_model.conv1 = torch.nn.Conv2d(\n",
    "    in_channels = 3, out_channels = 64,\n",
    "    kernel_size = (3, 3), stride = (1, 1),\n",
    "    padding = (1, 1), bias = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-politics",
   "metadata": {
    "id": "9XuCGbCEZ42h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-charge",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ivaU7yfZ4_n",
    "outputId": "367d163d-3b25-4130-e87c-607936dc8145"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-bandwidth",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbk58181Z5ab",
    "outputId": "e1952a7f-7b21-4eee-d72d-f86c3249f12c"
   },
   "outputs": [],
   "source": [
    "# Move trained weights from Google Colab to Google Drive-\n",
    "# cp -rv ResNet50__finetuned_best_trained_loss.pth /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-people",
   "metadata": {
    "id": "wo0sOpcMaGtR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "informed-blackberry",
   "metadata": {
    "id": "46539cd4-cbf1-498f-8b4c-cdd7f1fa123c"
   },
   "outputs": [],
   "source": [
    "# PATH = '/home/arjun/Documents/Programs/Python_Codes/PyTorch_Resources/Good_Codes/Pruning_codes_and_resources/Good_Codes-Pruning/ResNet_Pruning_resources/ResNet50_Experiments/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "talented-monroe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "300c0595-6698-47a6-81e6-7b2bbf2b8028",
    "outputId": "ec33b000-3686-44cb-c30c-27b3d8f0eb66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained weights from above-\n",
    "# trained_model.load_state_dict(torch.load(PATH + \"ResNet50__finetuned_best_trained_loss.pth\", map_location = device))\n",
    "trained_model.load_state_dict(torch.load(\"ResNet50__finetuned_best_trained_loss.pth\", map_location = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-adapter",
   "metadata": {
    "id": "aea15b1f-9d50-43b6-9eb7-674d46d9ccab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "established-apparel",
   "metadata": {
    "id": "f4b50a45-c4d5-471c-b244-fba9530a2e94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place model on GPU-\n",
    "trained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-holiday",
   "metadata": {
    "id": "b4da83d1-a485-4fef-928b-187f15324092"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-skiing",
   "metadata": {
    "id": "e26ce4e5-627b-45af-8c90-4555a82d2dad"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "urban-opinion",
   "metadata": {},
   "source": [
    "## PyTorch Pruning:\n",
    "\n",
    "- [Reference blog](https://leimao.github.io/blog/PyTorch-Pruning/)\n",
    "\n",
    "- [Reference GitHub](https://github.com/leimao/PyTorch-Pruning-Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-decade",
   "metadata": {},
   "source": [
    "### Sparsity for Iterative Pruning\n",
    "\n",
    "The ```prune.l1_unstructured``` function uses an ```amount``` argument which could be either the percentage of connections to prune (if it is a float between 0 and 1), or the absolute number of connections to prune (if it is a non-negative integer).\n",
    "\n",
    "__When it is the percentage, it is the the relative percentage to the number of unmasked/remaining parameters in the module/layer__.\n",
    "For example, in iterative pruning, if we prune the weights of a certain layer by ```amount = 0.2``` in the first iteration and then prune the same module/layer by the same ```amount = 0.2``` in the second iteration. Then:\n",
    "- _the amount of the valid/surviving parameters after the second round of pruning will be 1 x (1 - 0.2) x (1 - 0.2), (and)_\n",
    "- _the sparsity of the parameters, i.e., the pruning rate/rate of pruning, in this module/layer will be: 1 - (1 x (1 - 0.2) x (1 - 0.2))_.\n",
    "\n",
    "\n",
    "Formally, the final prune rate could be calculated using the following equation. Suppose that the relative pruning rate for each iteration is $\\gamma$, the final pruning rate, after _n_ iterations, will be:\n",
    "$1-\\left(1-\\gamma\\right)^n$\n",
    "\n",
    "\n",
    "Similarly, it is also easy to derive the final pruning rate for the scenario that is different in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "developmental-pitch",
   "metadata": {
    "id": "5c8e4c95-7fbc-42a1-9b48-36f7b077cb4c"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, criterion = None):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        if criterion is not None:\n",
    "            loss = criterion(outputs, labels).item()\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    eval_loss = running_loss / len(test_loader.dataset)\n",
    "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
    "\n",
    "    return eval_loss, eval_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-briefing",
   "metadata": {
    "id": "2igA9YNYcH_S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "incorporate-option",
   "metadata": {
    "id": "sBQyz92ycIK3"
   },
   "outputs": [],
   "source": [
    "def create_classification_report(model, device, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            y_true += data[1].numpy().tolist()\n",
    "            images, _ = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred += predicted.cpu().numpy().tolist()\n",
    "\n",
    "    classification_report = sklearn.metrics.classification_report(\n",
    "        y_true = y_true, y_pred = y_pred)\n",
    "\n",
    "    return classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "billion-limitation",
   "metadata": {
    "id": "2WBDx3XkcLRY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "large-worship",
   "metadata": {
    "id": "4u9B3ZultnI6"
   },
   "outputs": [],
   "source": [
    "def remove_parameters(model):\n",
    "\n",
    "    for module_name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            try:\n",
    "                prune.remove(module, \"weight\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                prune.remove(module, \"bias\")\n",
    "            except:\n",
    "                pass\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            try:\n",
    "                prune.remove(module, \"weight\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                prune.remove(module, \"bias\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "unexpected-graph",
   "metadata": {
    "id": "alLzC6-Rtnii"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "exclusive-gibraltar",
   "metadata": {
    "id": "NePRZMnWtn-3"
   },
   "outputs": [],
   "source": [
    "def compute_final_pruning_rate(pruning_rate, num_iterations):\n",
    "    '''\n",
    "    A function to compute the final pruning rate for iterative pruning.\n",
    "        Note that this cannot be applied for global pruning rate if the pruning rate is heterogeneous among different layers.\n",
    "    Args:\n",
    "        pruning_rate (float): Pruning rate.\n",
    "        num_iterations (int): Number of iterations.\n",
    "    Returns:\n",
    "        float: Final pruning rate.\n",
    "    '''\n",
    "\n",
    "    final_pruning_rate = 1 - (1 - pruning_rate) ** num_iterations\n",
    "\n",
    "    return final_pruning_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "piano-power",
   "metadata": {
    "id": "08x_Gbn-tqgC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "romantic-female",
   "metadata": {
    "id": "o5Q3K_kEtqoS"
   },
   "outputs": [],
   "source": [
    "def measure_module_sparsity(module, weight=True, bias=False, use_mask=False):\n",
    "\n",
    "    num_zeros = 0\n",
    "    num_elements = 0\n",
    "\n",
    "    if use_mask == True:\n",
    "        for buffer_name, buffer in module.named_buffers():\n",
    "            if \"weight_mask\" in buffer_name and weight == True:\n",
    "                num_zeros += torch.sum(buffer == 0).item()\n",
    "                num_elements += buffer.nelement()\n",
    "            if \"bias_mask\" in buffer_name and bias == True:\n",
    "                num_zeros += torch.sum(buffer == 0).item()\n",
    "                num_elements += buffer.nelement()\n",
    "    else:\n",
    "        for param_name, param in module.named_parameters():\n",
    "            if \"weight\" in param_name and weight == True:\n",
    "                num_zeros += torch.sum(param == 0).item()\n",
    "                num_elements += param.nelement()\n",
    "            if \"bias\" in param_name and bias == True:\n",
    "                num_zeros += torch.sum(param == 0).item()\n",
    "                num_elements += param.nelement()\n",
    "\n",
    "    sparsity = num_zeros / num_elements\n",
    "\n",
    "    return num_zeros, num_elements, sparsity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "final-prayer",
   "metadata": {
    "id": "Dg4iABhvtth4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "destroyed-fabric",
   "metadata": {
    "id": "_Nt7szsPttoz"
   },
   "outputs": [],
   "source": [
    "def measure_global_sparsity(\n",
    "    model, weight = True,\n",
    "    bias = False, conv2d_use_mask = False,\n",
    "    linear_use_mask = False):\n",
    "\n",
    "    num_zeros = 0\n",
    "    num_elements = 0\n",
    "\n",
    "    for module_name, module in model.named_modules():\n",
    "\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "\n",
    "            module_num_zeros, module_num_elements, _ = measure_module_sparsity(\n",
    "                module, weight=weight, bias=bias, use_mask=conv2d_use_mask)\n",
    "            num_zeros += module_num_zeros\n",
    "            num_elements += module_num_elements\n",
    "\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "\n",
    "            module_num_zeros, module_num_elements, _ = measure_module_sparsity(\n",
    "                module, weight=weight, bias=bias, use_mask=linear_use_mask)\n",
    "            num_zeros += module_num_zeros\n",
    "            num_elements += module_num_elements\n",
    "\n",
    "    sparsity = num_zeros / num_elements\n",
    "\n",
    "    return num_zeros, num_elements, sparsity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-johnston",
   "metadata": {
    "id": "8Y5XR4JttwEh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-first",
   "metadata": {
    "id": "1cb65390-0bd9-458d-a27f-0e68d6ae63e5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sitting-premises",
   "metadata": {
    "id": "52bf2547-dd4a-45f3-95ec-b1cb5eb3e762"
   },
   "source": [
    "### torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=-1, verbose=False)\n",
    "[refer](https://pytorch.org/docs/stable/optim.html)\n",
    "\n",
    "Decays the learning rate of each parameter group by 'gamma' once the number of epoch reaches one of the milestones. Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler. When ```last_epoch = -1```, sets initial lr as lr.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "- optimizer (Optimizer) – Wrapped optimizer.\n",
    "\n",
    "- milestones (list) – List of epoch indices. Must be increasing.\n",
    "\n",
    "- gamma (float) – Multiplicative factor of learning rate decay. Default: 0.1.\n",
    "\n",
    "- last_epoch (int) – The index of last epoch. Default: -1.\n",
    "\n",
    "- verbose (bool) – If True, prints a message to stdout for each update. Default: False.\n",
    "\n",
    "Example:\n",
    "```\n",
    "# Assuming optimizer uses lr = 0.05 for all groups\n",
    ">>> # lr = 0.05     if epoch < 30\n",
    ">>> # lr = 0.005    if 30 <= epoch < 80\n",
    ">>> # lr = 0.0005   if epoch >= 80\n",
    ">>> scheduler = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)\n",
    ">>> for epoch in range(100):\n",
    ">>>     train(...)\n",
    ">>>     validate(...)\n",
    ">>>     scheduler.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fewer-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 10\n",
    "# random_seed = 1\n",
    "l1_regularization_strength = 0\n",
    "l2_regularization_strength = 1e-4\n",
    "learning_rate = 0.01\n",
    "learning_rate_decay = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "judicial-climate",
   "metadata": {
    "id": "06abeecd-82c7-4446-8acc-1f9f32a1903f"
   },
   "outputs": [],
   "source": [
    "def fine_tune_train_model(model, train_loader, test_loader, device, l1_regularization_strength = 0,\n",
    "                l2_regularization_strength = 1e-4, learning_rate = 1e-1, num_epochs = 20):\n",
    "\n",
    "    # The training configurations were not carefully selected.\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # It seems that SGD optimizer is better than Adam optimizer for ResNet18 training on CIFAR10-\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr = learning_rate,\n",
    "        momentum = 0.9, weight_decay = l2_regularization_strength\n",
    "    )\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    \n",
    "    # Define learning rate scheduler-\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        # optimizer, milestones = [100, 150],\n",
    "        optimizer, milestones = [8, 15],\n",
    "        gamma = 0.1, last_epoch = -1)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n",
    "    \n",
    "\n",
    "    # Evaluation-\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = evaluate_model(\n",
    "        model = model, test_loader = test_loader,\n",
    "        device = device, criterion = criterion)\n",
    "    \n",
    "    print(f\"Pre fine-tuning: val_loss = {eval_loss:.3f} & val_accuracy = {eval_accuracy * 100:.3f}%\")\n",
    "    # print(\"Epoch: {:03d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(0, eval_loss, eval_accuracy))\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            l1_reg = torch.tensor(0.).to(device)\n",
    "            for module in model.modules():\n",
    "                mask = None\n",
    "                weight = None\n",
    "                for name, buffer in module.named_buffers():\n",
    "                    if name == \"weight_mask\":\n",
    "                        mask = buffer\n",
    "                for name, param in module.named_parameters():\n",
    "                    if name == \"weight_orig\":\n",
    "                        weight = param\n",
    "                # We usually only want to introduce sparsity to weights and prune weights.\n",
    "                # Do the same for bias if necessary.\n",
    "                if mask is not None and weight is not None:\n",
    "                    l1_reg += torch.norm(mask * weight, 1)\n",
    "\n",
    "            loss += l1_regularization_strength * l1_reg\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        eval_loss, eval_accuracy = evaluate_model(\n",
    "            model = model, test_loader = test_loader,\n",
    "            device = device, criterion = criterion)\n",
    "\n",
    "        # Set learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        '''\n",
    "        print(\n",
    "            \"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\"\n",
    "            .format(epoch + 1, train_loss, train_accuracy, eval_loss,\n",
    "                    eval_accuracy))\n",
    "        '''\n",
    "        print(f\"epoch = {epoch + 1} loss = {train_loss:.3f}, accuracy = {train_accuracy * 100:.3f}%, val_loss = {eval_loss:.3f}, val_accuracy = {eval_accuracy * 100:.3f}% & LR: {optimizer.param_groups[0]['lr']:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "quarterly-daily",
   "metadata": {
    "id": "b167c5a7-0d58-4417-b76f-d0c8d42020b7"
   },
   "outputs": [],
   "source": [
    "# Sanity check-\n",
    "# fine_tuned_model = fine_tune_train_model(trained_model, train_loader, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-prague",
   "metadata": {
    "id": "e7a7f35f-ad0f-40b2-8b8a-19a5913ac836"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-matthew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-facility",
   "metadata": {},
   "source": [
    "### Available Pruning Methods:\n",
    "\n",
    "The following child classes inherit from the ```BasePruningMethod```:\n",
    "\n",
    "- ```torch.nn.utils.prune.Identity```: utility pruning method that does not prune any units but generates the pruning parametrization with a mask of ones;\n",
    "\n",
    "- ```torch.nn.utils.prune.RandomUnstructured```: prune (currently unpruned) entries in a tensor at random;\n",
    "\n",
    "- ```torch.nn.utils.prune.L1Unstructured```: prune (currently unpruned) entries in a tensor __by zeroing out the ones with the lowest absolute magnitude__;\n",
    "\n",
    "- ```torch.nn.utils.prune.RandomStructured```: prune entire (currently unpruned)rows or columns in a tensor random;\n",
    "\n",
    "- ```torch.nn.utils.prune.LnStructured```:  prune entire (currently unpruned) rows or columns in a tensor based on their $L_n$-norm (supported values of _n_ correspond to sup-ported values for argument _p_ in ```torch.norm()```);\n",
    "\n",
    "- ```torch.nn.utils.prune.CustomFromMask```: prune a tensor using a user-provided mask.\n",
    "\n",
    "\n",
    "Refer to \"STREAMLINING TENSOR AND NETWORK PRUNING IN PYTORCH\" by Michela Paganini et al. research paper for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-castle",
   "metadata": {
    "id": "b40e9f73-b3a3-4126-8a27-9ea825307a5b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "considered-guarantee",
   "metadata": {
    "id": "6cea484d-ee61-4065-acea-b0e3bd526de3"
   },
   "outputs": [],
   "source": [
    "def iterative_pruning_finetuning(\n",
    "    model, train_loader, test_loader, device,\n",
    "    learning_rate, l1_regularization_strength,\n",
    "    l2_regularization_strength, learning_rate_decay = 0.1,\n",
    "    conv2d_prune_amount = 0.2, linear_prune_amount = 0.1,\n",
    "    num_iterations = 10, num_epochs_per_iteration = 10,\n",
    "    model_filename_prefix = \"pruned_model\", model_dir = \"saved_models\",\n",
    "    grouped_pruning = False):\n",
    "    \n",
    "    '''\n",
    "    num_iterations - number of pruning iterations/rounds\n",
    "    num_epochs_per_iteration - number of fine-tuning rounds\n",
    "    '''\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        print(\"\\nPruning and Finetuning {}/{}\".format(i + 1, num_iterations))\n",
    "\n",
    "        print(\"Pruning...\")\n",
    "\n",
    "\n",
    "        # NOTE: For global pruning, linear/dense layer can also be pruned!\n",
    "        if grouped_pruning == True:\n",
    "            # grouped_pruning -> Global pruning\n",
    "            parameters_to_prune = []\n",
    "            for module_name, module in model.named_modules():\n",
    "                if isinstance(module, torch.nn.Conv2d):\n",
    "                    parameters_to_prune.append((module, \"weight\"))\n",
    "                elif isinstance(module, torch.nn.Linear):\n",
    "                    parameters_to_prune.append((module, \"weight\"))\n",
    "        \n",
    "            # L1Unstructured - prune (currently unpruned) entries in a tensor by zeroing\n",
    "            # out the ones with the lowest absolute magnitude-\n",
    "            prune.global_unstructured(\n",
    "                parameters_to_prune,\n",
    "                pruning_method = prune.L1Unstructured,\n",
    "                amount = conv2d_prune_amount,\n",
    "            )\n",
    "        \n",
    "        # layer-wise pruning-\n",
    "        else:\n",
    "            for module_name, module in model.named_modules():\n",
    "                if isinstance(module, torch.nn.Conv2d):\n",
    "                    prune.l1_unstructured(\n",
    "                        module, name = \"weight\",\n",
    "                        amount = conv2d_prune_amount)\n",
    "                elif isinstance(module, torch.nn.Linear):\n",
    "                    prune.l1_unstructured(\n",
    "                        module, name = \"weight\",\n",
    "                        amount = linear_prune_amount)\n",
    "\n",
    "        # Compute validation accuracy just after pruning-\n",
    "        _, eval_accuracy = evaluate_model(\n",
    "            model = model, test_loader = test_loader,\n",
    "            device = device, criterion = None)\n",
    "\n",
    "        '''\n",
    "        classification_report = create_classification_report(\n",
    "            model=model, test_loader=test_loader, device=device)\n",
    "        '''\n",
    "\n",
    "        # Compute global sparsity-\n",
    "        num_zeros, num_elements, sparsity = measure_global_sparsity(\n",
    "            model, weight = True,\n",
    "            bias = False, conv2d_use_mask = True,\n",
    "            linear_use_mask = False)\n",
    "        \n",
    "        print(f\"Global sparsity = {sparsity * 100:.3f}% & val_accuracy = {eval_accuracy * 100:.3f}%\")\n",
    "        # print(model.conv1._forward_pre_hooks)\n",
    "\n",
    "        print(\"\\nFine-tuning...\")\n",
    "\n",
    "        fine_tuned_model = fine_tune_train_model(\n",
    "            model = model, train_loader = train_loader,\n",
    "            test_loader = test_loader, device = device,\n",
    "            l1_regularization_strength = l1_regularization_strength,\n",
    "            l2_regularization_strength = l2_regularization_strength,\n",
    "            # i -> current pruning round-\n",
    "            # learning_rate = learning_rate * (learning_rate_decay ** i),\n",
    "            learning_rate = learning_rate,\n",
    "            num_epochs = num_epochs_per_iteration)\n",
    "\n",
    "        _, eval_accuracy = evaluate_model(\n",
    "            model=model, test_loader = test_loader,\n",
    "            device = device, criterion = None)\n",
    "\n",
    "        '''\n",
    "        classification_report = create_classification_report(\n",
    "            model=model, test_loader=test_loader, device=device)\n",
    "        '''\n",
    "\n",
    "        num_zeros, num_elements, sparsity = measure_global_sparsity(\n",
    "            # model,\n",
    "            fine_tuned_model, weight = True,\n",
    "            bias = False, conv2d_use_mask = True,\n",
    "            linear_use_mask = False)\n",
    "\n",
    "        print(f\"Post fine-tuning: Global sparsity = {sparsity * 100:.3f}% & val_accuracy = {eval_accuracy * 100:.3f}%\")\n",
    "\n",
    "        '''\n",
    "        model_filename = \"{}_{}.pt\".format(model_filename_prefix, i + 1)\n",
    "        model_filepath = os.path.join(model_dir, model_filename)\n",
    "        save_model(model=model,\n",
    "                   model_dir=model_dir,\n",
    "                   model_filename=model_filename)\n",
    "        model = load_model(model=model,\n",
    "                           model_filepath=model_filepath,\n",
    "                           device=device)\n",
    "        '''\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-engineer",
   "metadata": {
    "id": "55971543-d1d1-4f21-9ac0-f7cdcb53c13a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-poetry",
   "metadata": {
    "id": "0bf03de4-e2e8-403f-a67c-1fbe79df2830"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bacterial-physics",
   "metadata": {
    "id": "af83a955-ea75-486f-8818-b5de1d569845"
   },
   "outputs": [],
   "source": [
    "_, eval_accuracy = evaluate_model(\n",
    "    model = trained_model, test_loader=test_loader,\n",
    "    device = device, criterion = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mobile-integration",
   "metadata": {
    "id": "713d872a-970f-4cd5-8977-c08bbacac246"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "classification_report = create_classification_report(\n",
    "    model = trained_model, test_loader = test_loader,\n",
    "    device = device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "proprietary-taste",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2af261e3-beae-4715-a0bc-d43d643a271a",
    "outputId": "0d700751-7120-49a9-ab2a-b87e87624364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity = 0.000% & val_accuracy = 92.580%\n"
     ]
    }
   ],
   "source": [
    "num_zeros, num_elements, sparsity = measure_global_sparsity(trained_model)\n",
    "print(f\"Global sparsity = {sparsity:.3f}% & val_accuracy = {eval_accuracy * 100:.3f}%\")\n",
    "\n",
    "# print(\"Test Accuracy: {:.3f}\".format(eval_accuracy))\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report)\n",
    "# print(\"Global Sparsity:\")\n",
    "# print(\"{:.2f}\".format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-hindu",
   "metadata": {
    "id": "72664f76-d5ad-4529-ab07-fd4b737adc59"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "logical-healthcare",
   "metadata": {
    "id": "b6ef6922-a092-48ee-ab48-ba9fec2e442e"
   },
   "outputs": [],
   "source": [
    "model_dir = \"saved_models\"\n",
    "model_filename = \"resnet50_cifar10.pth\"\n",
    "model_filename_prefix = \"pruned_model\"\n",
    "pruned_model_filename = \"resnet50_pruned_cifar10.pth\"\n",
    "model_filepath = os.path.join(model_dir, model_filename)\n",
    "pruned_model_filepath = os.path.join(model_dir, pruned_model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-standing",
   "metadata": {
    "id": "1TxqT9YXXQ52"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "covered-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-table",
   "metadata": {
    "id": "w7LP_7tIXRFS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "driven-framing",
   "metadata": {
    "id": "21531339-69ff-47cd-b480-0a04bf362b2c"
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "suspended-lawyer",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cc8bffa-4def-4174-9f67-9a0748209717",
    "outputId": "940697a5-17e7-4ef0-a50d-7ada9846b406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterative Pruning + Fine-Tuning...\n"
     ]
    }
   ],
   "source": [
    "print(\"Iterative Pruning + Fine-Tuning...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "peaceful-strength",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b4787ad-32ac-4083-bb48-fd19af860a1e",
    "outputId": "4c95577b-7f90-47f4-909d-e290cb8b5ff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruning and Finetuning 1/21\n",
      "Pruning...\n",
      "Global sparsity = 19.991% & val_accuracy = 92.520%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.238 & val_accuracy = 92.520%\n",
      "epoch = 1 loss = 0.236, accuracy = 91.884%, val_loss = 0.253, val_accuracy = 91.550% & LR: 0.0100\n",
      "epoch = 2 loss = 0.181, accuracy = 93.674%, val_loss = 0.238, val_accuracy = 91.880% & LR: 0.0100\n",
      "epoch = 3 loss = 0.159, accuracy = 94.530%, val_loss = 0.258, val_accuracy = 91.510% & LR: 0.0100\n",
      "epoch = 4 loss = 0.142, accuracy = 94.998%, val_loss = 0.261, val_accuracy = 91.850% & LR: 0.0100\n",
      "epoch = 5 loss = 0.130, accuracy = 95.322%, val_loss = 0.263, val_accuracy = 91.740% & LR: 0.0100\n",
      "epoch = 6 loss = 0.119, accuracy = 95.756%, val_loss = 0.258, val_accuracy = 92.040% & LR: 0.0100\n",
      "epoch = 7 loss = 0.111, accuracy = 96.096%, val_loss = 0.251, val_accuracy = 92.170% & LR: 0.0100\n",
      "epoch = 8 loss = 0.103, accuracy = 96.316%, val_loss = 0.262, val_accuracy = 92.080% & LR: 0.0010\n",
      "epoch = 9 loss = 0.066, accuracy = 97.704%, val_loss = 0.224, val_accuracy = 93.060% & LR: 0.0010\n",
      "epoch = 10 loss = 0.053, accuracy = 98.270%, val_loss = 0.229, val_accuracy = 93.380% & LR: 0.0010\n",
      "epoch = 11 loss = 0.044, accuracy = 98.512%, val_loss = 0.232, val_accuracy = 93.340% & LR: 0.0010\n",
      "epoch = 12 loss = 0.042, accuracy = 98.584%, val_loss = 0.237, val_accuracy = 93.110% & LR: 0.0010\n",
      "epoch = 13 loss = 0.038, accuracy = 98.730%, val_loss = 0.236, val_accuracy = 93.560% & LR: 0.0010\n",
      "epoch = 14 loss = 0.037, accuracy = 98.716%, val_loss = 0.237, val_accuracy = 93.430% & LR: 0.0010\n",
      "epoch = 15 loss = 0.035, accuracy = 98.786%, val_loss = 0.241, val_accuracy = 93.450% & LR: 0.0001\n",
      "epoch = 16 loss = 0.031, accuracy = 98.948%, val_loss = 0.241, val_accuracy = 93.510% & LR: 0.0001\n",
      "epoch = 17 loss = 0.032, accuracy = 98.958%, val_loss = 0.239, val_accuracy = 93.620% & LR: 0.0001\n",
      "epoch = 18 loss = 0.030, accuracy = 99.026%, val_loss = 0.244, val_accuracy = 93.410% & LR: 0.0001\n",
      "epoch = 19 loss = 0.030, accuracy = 98.998%, val_loss = 0.246, val_accuracy = 93.510% & LR: 0.0001\n",
      "epoch = 20 loss = 0.029, accuracy = 99.030%, val_loss = 0.242, val_accuracy = 93.490% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 19.991% & val_accuracy = 93.490%\n",
      "\n",
      "Pruning and Finetuning 2/21\n",
      "Pruning...\n",
      "Global sparsity = 35.982% & val_accuracy = 93.470%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.258 & val_accuracy = 93.470%\n",
      "epoch = 1 loss = 0.071, accuracy = 97.508%, val_loss = 0.271, val_accuracy = 91.970% & LR: 0.0100\n",
      "epoch = 2 loss = 0.075, accuracy = 97.346%, val_loss = 0.253, val_accuracy = 92.820% & LR: 0.0100\n",
      "epoch = 3 loss = 0.072, accuracy = 97.418%, val_loss = 0.283, val_accuracy = 91.830% & LR: 0.0100\n",
      "epoch = 4 loss = 0.067, accuracy = 97.692%, val_loss = 0.269, val_accuracy = 92.670% & LR: 0.0100\n",
      "epoch = 5 loss = 0.062, accuracy = 97.838%, val_loss = 0.288, val_accuracy = 92.120% & LR: 0.0100\n",
      "epoch = 6 loss = 0.060, accuracy = 97.894%, val_loss = 0.285, val_accuracy = 92.390% & LR: 0.0100\n",
      "epoch = 7 loss = 0.060, accuracy = 97.886%, val_loss = 0.284, val_accuracy = 92.210% & LR: 0.0100\n",
      "epoch = 8 loss = 0.054, accuracy = 98.110%, val_loss = 0.303, val_accuracy = 92.070% & LR: 0.0010\n",
      "epoch = 9 loss = 0.036, accuracy = 98.752%, val_loss = 0.253, val_accuracy = 92.990% & LR: 0.0010\n",
      "epoch = 10 loss = 0.027, accuracy = 99.112%, val_loss = 0.251, val_accuracy = 93.310% & LR: 0.0010\n",
      "epoch = 11 loss = 0.022, accuracy = 99.256%, val_loss = 0.256, val_accuracy = 93.330% & LR: 0.0010\n",
      "epoch = 12 loss = 0.019, accuracy = 99.362%, val_loss = 0.262, val_accuracy = 93.450% & LR: 0.0010\n",
      "epoch = 13 loss = 0.017, accuracy = 99.410%, val_loss = 0.265, val_accuracy = 93.450% & LR: 0.0010\n",
      "epoch = 14 loss = 0.017, accuracy = 99.394%, val_loss = 0.273, val_accuracy = 93.340% & LR: 0.0010\n",
      "epoch = 15 loss = 0.015, accuracy = 99.498%, val_loss = 0.274, val_accuracy = 93.520% & LR: 0.0001\n",
      "epoch = 16 loss = 0.016, accuracy = 99.478%, val_loss = 0.276, val_accuracy = 93.410% & LR: 0.0001\n",
      "epoch = 17 loss = 0.013, accuracy = 99.554%, val_loss = 0.276, val_accuracy = 93.550% & LR: 0.0001\n",
      "epoch = 18 loss = 0.014, accuracy = 99.546%, val_loss = 0.273, val_accuracy = 93.480% & LR: 0.0001\n",
      "epoch = 19 loss = 0.014, accuracy = 99.532%, val_loss = 0.272, val_accuracy = 93.500% & LR: 0.0001\n",
      "epoch = 20 loss = 0.013, accuracy = 99.568%, val_loss = 0.277, val_accuracy = 93.430% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 35.982% & val_accuracy = 93.430%\n",
      "\n",
      "Pruning and Finetuning 3/21\n",
      "Pruning...\n",
      "Global sparsity = 48.778% & val_accuracy = 93.240%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.300 & val_accuracy = 93.240%\n",
      "epoch = 1 loss = 0.044, accuracy = 98.424%, val_loss = 0.300, val_accuracy = 92.270% & LR: 0.0100\n",
      "epoch = 2 loss = 0.045, accuracy = 98.360%, val_loss = 0.279, val_accuracy = 92.730% & LR: 0.0100\n",
      "epoch = 3 loss = 0.044, accuracy = 98.510%, val_loss = 0.293, val_accuracy = 92.410% & LR: 0.0100\n",
      "epoch = 4 loss = 0.039, accuracy = 98.642%, val_loss = 0.310, val_accuracy = 92.350% & LR: 0.0100\n",
      "epoch = 5 loss = 0.041, accuracy = 98.572%, val_loss = 0.303, val_accuracy = 92.370% & LR: 0.0100\n",
      "epoch = 6 loss = 0.040, accuracy = 98.574%, val_loss = 0.285, val_accuracy = 93.000% & LR: 0.0100\n",
      "epoch = 7 loss = 0.039, accuracy = 98.608%, val_loss = 0.294, val_accuracy = 92.560% & LR: 0.0100\n",
      "epoch = 8 loss = 0.036, accuracy = 98.790%, val_loss = 0.291, val_accuracy = 92.850% & LR: 0.0010\n",
      "epoch = 9 loss = 0.022, accuracy = 99.242%, val_loss = 0.266, val_accuracy = 93.230% & LR: 0.0010\n",
      "epoch = 10 loss = 0.017, accuracy = 99.440%, val_loss = 0.261, val_accuracy = 93.390% & LR: 0.0010\n",
      "epoch = 11 loss = 0.013, accuracy = 99.574%, val_loss = 0.263, val_accuracy = 93.420% & LR: 0.0010\n",
      "epoch = 12 loss = 0.012, accuracy = 99.626%, val_loss = 0.266, val_accuracy = 93.350% & LR: 0.0010\n",
      "epoch = 13 loss = 0.010, accuracy = 99.652%, val_loss = 0.268, val_accuracy = 93.610% & LR: 0.0010\n",
      "epoch = 14 loss = 0.010, accuracy = 99.664%, val_loss = 0.269, val_accuracy = 93.610% & LR: 0.0010\n",
      "epoch = 15 loss = 0.008, accuracy = 99.724%, val_loss = 0.279, val_accuracy = 93.640% & LR: 0.0001\n",
      "epoch = 16 loss = 0.008, accuracy = 99.742%, val_loss = 0.277, val_accuracy = 93.670% & LR: 0.0001\n",
      "epoch = 17 loss = 0.009, accuracy = 99.716%, val_loss = 0.277, val_accuracy = 93.610% & LR: 0.0001\n",
      "epoch = 18 loss = 0.008, accuracy = 99.748%, val_loss = 0.278, val_accuracy = 93.700% & LR: 0.0001\n",
      "epoch = 19 loss = 0.008, accuracy = 99.750%, val_loss = 0.279, val_accuracy = 93.610% & LR: 0.0001\n",
      "epoch = 20 loss = 0.008, accuracy = 99.768%, val_loss = 0.279, val_accuracy = 93.530% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 48.778% & val_accuracy = 93.530%\n",
      "\n",
      "Pruning and Finetuning 4/21\n",
      "Pruning...\n",
      "Global sparsity = 59.015% & val_accuracy = 93.040%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.310 & val_accuracy = 93.040%\n",
      "epoch = 1 loss = 0.030, accuracy = 98.948%, val_loss = 0.302, val_accuracy = 92.590% & LR: 0.0100\n",
      "epoch = 2 loss = 0.036, accuracy = 98.720%, val_loss = 0.285, val_accuracy = 92.800% & LR: 0.0100\n",
      "epoch = 3 loss = 0.034, accuracy = 98.824%, val_loss = 0.309, val_accuracy = 92.700% & LR: 0.0100\n",
      "epoch = 4 loss = 0.032, accuracy = 98.896%, val_loss = 0.306, val_accuracy = 92.820% & LR: 0.0100\n",
      "epoch = 5 loss = 0.028, accuracy = 99.026%, val_loss = 0.319, val_accuracy = 92.640% & LR: 0.0100\n",
      "epoch = 6 loss = 0.030, accuracy = 98.946%, val_loss = 0.298, val_accuracy = 92.670% & LR: 0.0100\n",
      "epoch = 7 loss = 0.027, accuracy = 99.098%, val_loss = 0.306, val_accuracy = 93.030% & LR: 0.0100\n",
      "epoch = 8 loss = 0.026, accuracy = 99.106%, val_loss = 0.326, val_accuracy = 92.350% & LR: 0.0010\n",
      "epoch = 9 loss = 0.016, accuracy = 99.458%, val_loss = 0.291, val_accuracy = 93.160% & LR: 0.0010\n",
      "epoch = 10 loss = 0.013, accuracy = 99.580%, val_loss = 0.287, val_accuracy = 93.350% & LR: 0.0010\n",
      "epoch = 11 loss = 0.010, accuracy = 99.658%, val_loss = 0.288, val_accuracy = 93.490% & LR: 0.0010\n",
      "epoch = 12 loss = 0.008, accuracy = 99.722%, val_loss = 0.287, val_accuracy = 93.450% & LR: 0.0010\n",
      "epoch = 13 loss = 0.007, accuracy = 99.798%, val_loss = 0.288, val_accuracy = 93.560% & LR: 0.0010\n",
      "epoch = 14 loss = 0.007, accuracy = 99.778%, val_loss = 0.289, val_accuracy = 93.680% & LR: 0.0010\n",
      "epoch = 15 loss = 0.006, accuracy = 99.834%, val_loss = 0.294, val_accuracy = 93.550% & LR: 0.0001\n",
      "epoch = 16 loss = 0.006, accuracy = 99.798%, val_loss = 0.290, val_accuracy = 93.640% & LR: 0.0001\n",
      "epoch = 17 loss = 0.006, accuracy = 99.818%, val_loss = 0.293, val_accuracy = 93.590% & LR: 0.0001\n",
      "epoch = 18 loss = 0.006, accuracy = 99.806%, val_loss = 0.293, val_accuracy = 93.650% & LR: 0.0001\n",
      "epoch = 19 loss = 0.005, accuracy = 99.852%, val_loss = 0.293, val_accuracy = 93.540% & LR: 0.0001\n",
      "epoch = 20 loss = 0.006, accuracy = 99.834%, val_loss = 0.293, val_accuracy = 93.570% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 59.015% & val_accuracy = 93.570%\n",
      "\n",
      "Pruning and Finetuning 5/21\n",
      "Pruning...\n",
      "Global sparsity = 67.204% & val_accuracy = 93.080%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.323 & val_accuracy = 93.080%\n",
      "epoch = 1 loss = 0.031, accuracy = 98.964%, val_loss = 0.329, val_accuracy = 92.240% & LR: 0.0100\n",
      "epoch = 2 loss = 0.029, accuracy = 99.022%, val_loss = 0.327, val_accuracy = 92.680% & LR: 0.0100\n",
      "epoch = 3 loss = 0.029, accuracy = 99.042%, val_loss = 0.329, val_accuracy = 92.680% & LR: 0.0100\n",
      "epoch = 4 loss = 0.027, accuracy = 99.074%, val_loss = 0.303, val_accuracy = 93.030% & LR: 0.0100\n",
      "epoch = 5 loss = 0.026, accuracy = 99.088%, val_loss = 0.336, val_accuracy = 92.010% & LR: 0.0100\n",
      "epoch = 6 loss = 0.027, accuracy = 99.090%, val_loss = 0.314, val_accuracy = 92.810% & LR: 0.0100\n",
      "epoch = 7 loss = 0.025, accuracy = 99.080%, val_loss = 0.314, val_accuracy = 92.830% & LR: 0.0100\n",
      "epoch = 8 loss = 0.023, accuracy = 99.186%, val_loss = 0.336, val_accuracy = 92.700% & LR: 0.0010\n",
      "epoch = 9 loss = 0.014, accuracy = 99.538%, val_loss = 0.290, val_accuracy = 93.440% & LR: 0.0010\n",
      "epoch = 10 loss = 0.009, accuracy = 99.694%, val_loss = 0.290, val_accuracy = 93.640% & LR: 0.0010\n",
      "epoch = 11 loss = 0.007, accuracy = 99.772%, val_loss = 0.291, val_accuracy = 93.760% & LR: 0.0010\n",
      "epoch = 12 loss = 0.007, accuracy = 99.794%, val_loss = 0.297, val_accuracy = 93.700% & LR: 0.0010\n",
      "epoch = 13 loss = 0.006, accuracy = 99.814%, val_loss = 0.295, val_accuracy = 93.750% & LR: 0.0010\n",
      "epoch = 14 loss = 0.006, accuracy = 99.828%, val_loss = 0.302, val_accuracy = 93.770% & LR: 0.0010\n",
      "epoch = 15 loss = 0.006, accuracy = 99.822%, val_loss = 0.300, val_accuracy = 93.880% & LR: 0.0001\n",
      "epoch = 16 loss = 0.005, accuracy = 99.822%, val_loss = 0.299, val_accuracy = 93.900% & LR: 0.0001\n",
      "epoch = 17 loss = 0.005, accuracy = 99.854%, val_loss = 0.298, val_accuracy = 93.930% & LR: 0.0001\n",
      "epoch = 18 loss = 0.005, accuracy = 99.868%, val_loss = 0.302, val_accuracy = 93.890% & LR: 0.0001\n",
      "epoch = 19 loss = 0.005, accuracy = 99.872%, val_loss = 0.299, val_accuracy = 93.990% & LR: 0.0001\n",
      "epoch = 20 loss = 0.005, accuracy = 99.842%, val_loss = 0.300, val_accuracy = 93.930% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 67.204% & val_accuracy = 93.930%\n",
      "\n",
      "Pruning and Finetuning 6/21\n",
      "Pruning...\n",
      "Global sparsity = 73.755% & val_accuracy = 93.110%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.353 & val_accuracy = 93.110%\n",
      "epoch = 1 loss = 0.030, accuracy = 99.026%, val_loss = 0.327, val_accuracy = 92.830% & LR: 0.0100\n",
      "epoch = 2 loss = 0.029, accuracy = 99.008%, val_loss = 0.310, val_accuracy = 93.240% & LR: 0.0100\n",
      "epoch = 3 loss = 0.026, accuracy = 99.098%, val_loss = 0.319, val_accuracy = 93.180% & LR: 0.0100\n",
      "epoch = 4 loss = 0.023, accuracy = 99.204%, val_loss = 0.306, val_accuracy = 93.150% & LR: 0.0100\n",
      "epoch = 5 loss = 0.023, accuracy = 99.218%, val_loss = 0.298, val_accuracy = 93.240% & LR: 0.0100\n",
      "epoch = 6 loss = 0.022, accuracy = 99.284%, val_loss = 0.310, val_accuracy = 93.260% & LR: 0.0100\n",
      "epoch = 7 loss = 0.023, accuracy = 99.216%, val_loss = 0.314, val_accuracy = 92.910% & LR: 0.0100\n",
      "epoch = 8 loss = 0.022, accuracy = 99.228%, val_loss = 0.310, val_accuracy = 93.110% & LR: 0.0010\n",
      "epoch = 9 loss = 0.015, accuracy = 99.502%, val_loss = 0.283, val_accuracy = 93.450% & LR: 0.0010\n",
      "epoch = 10 loss = 0.010, accuracy = 99.684%, val_loss = 0.279, val_accuracy = 93.720% & LR: 0.0010\n",
      "epoch = 11 loss = 0.009, accuracy = 99.732%, val_loss = 0.282, val_accuracy = 93.740% & LR: 0.0010\n",
      "epoch = 12 loss = 0.008, accuracy = 99.780%, val_loss = 0.281, val_accuracy = 93.810% & LR: 0.0010\n",
      "epoch = 13 loss = 0.006, accuracy = 99.798%, val_loss = 0.281, val_accuracy = 93.750% & LR: 0.0010\n",
      "epoch = 14 loss = 0.005, accuracy = 99.860%, val_loss = 0.282, val_accuracy = 93.840% & LR: 0.0010\n",
      "epoch = 15 loss = 0.005, accuracy = 99.852%, val_loss = 0.285, val_accuracy = 94.000% & LR: 0.0001\n",
      "epoch = 16 loss = 0.005, accuracy = 99.842%, val_loss = 0.286, val_accuracy = 94.000% & LR: 0.0001\n",
      "epoch = 17 loss = 0.005, accuracy = 99.848%, val_loss = 0.286, val_accuracy = 93.950% & LR: 0.0001\n",
      "epoch = 18 loss = 0.005, accuracy = 99.862%, val_loss = 0.284, val_accuracy = 93.900% & LR: 0.0001\n",
      "epoch = 19 loss = 0.005, accuracy = 99.822%, val_loss = 0.289, val_accuracy = 93.940% & LR: 0.0001\n",
      "epoch = 20 loss = 0.004, accuracy = 99.874%, val_loss = 0.286, val_accuracy = 93.930% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 73.755% & val_accuracy = 93.930%\n",
      "\n",
      "Pruning and Finetuning 7/21\n",
      "Pruning...\n",
      "Global sparsity = 78.996% & val_accuracy = 92.690%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.323 & val_accuracy = 92.690%\n",
      "epoch = 1 loss = 0.030, accuracy = 98.970%, val_loss = 0.317, val_accuracy = 92.580% & LR: 0.0100\n",
      "epoch = 2 loss = 0.030, accuracy = 98.974%, val_loss = 0.304, val_accuracy = 93.090% & LR: 0.0100\n",
      "epoch = 3 loss = 0.024, accuracy = 99.142%, val_loss = 0.317, val_accuracy = 93.070% & LR: 0.0100\n",
      "epoch = 4 loss = 0.026, accuracy = 99.112%, val_loss = 0.322, val_accuracy = 92.450% & LR: 0.0100\n",
      "epoch = 5 loss = 0.021, accuracy = 99.304%, val_loss = 0.314, val_accuracy = 92.800% & LR: 0.0100\n",
      "epoch = 6 loss = 0.023, accuracy = 99.210%, val_loss = 0.322, val_accuracy = 92.920% & LR: 0.0100\n",
      "epoch = 7 loss = 0.021, accuracy = 99.246%, val_loss = 0.311, val_accuracy = 93.070% & LR: 0.0100\n",
      "epoch = 8 loss = 0.021, accuracy = 99.290%, val_loss = 0.346, val_accuracy = 92.630% & LR: 0.0010\n",
      "epoch = 9 loss = 0.015, accuracy = 99.482%, val_loss = 0.301, val_accuracy = 93.380% & LR: 0.0010\n",
      "epoch = 10 loss = 0.008, accuracy = 99.730%, val_loss = 0.293, val_accuracy = 93.510% & LR: 0.0010\n",
      "epoch = 11 loss = 0.008, accuracy = 99.758%, val_loss = 0.292, val_accuracy = 93.630% & LR: 0.0010\n",
      "epoch = 12 loss = 0.007, accuracy = 99.788%, val_loss = 0.292, val_accuracy = 93.610% & LR: 0.0010\n",
      "epoch = 13 loss = 0.006, accuracy = 99.824%, val_loss = 0.294, val_accuracy = 93.800% & LR: 0.0010\n",
      "epoch = 14 loss = 0.005, accuracy = 99.854%, val_loss = 0.295, val_accuracy = 93.790% & LR: 0.0010\n",
      "epoch = 15 loss = 0.005, accuracy = 99.856%, val_loss = 0.294, val_accuracy = 93.820% & LR: 0.0001\n",
      "epoch = 16 loss = 0.004, accuracy = 99.880%, val_loss = 0.295, val_accuracy = 93.790% & LR: 0.0001\n",
      "epoch = 17 loss = 0.004, accuracy = 99.876%, val_loss = 0.293, val_accuracy = 93.970% & LR: 0.0001\n",
      "epoch = 18 loss = 0.004, accuracy = 99.876%, val_loss = 0.292, val_accuracy = 93.840% & LR: 0.0001\n",
      "epoch = 19 loss = 0.004, accuracy = 99.866%, val_loss = 0.296, val_accuracy = 93.920% & LR: 0.0001\n",
      "epoch = 20 loss = 0.005, accuracy = 99.856%, val_loss = 0.293, val_accuracy = 93.960% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 78.996% & val_accuracy = 93.960%\n",
      "\n",
      "Pruning and Finetuning 8/21\n",
      "Pruning...\n",
      "Global sparsity = 83.188% & val_accuracy = 92.900%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.324 & val_accuracy = 92.900%\n",
      "epoch = 1 loss = 0.031, accuracy = 98.916%, val_loss = 0.334, val_accuracy = 92.300% & LR: 0.0100\n",
      "epoch = 2 loss = 0.027, accuracy = 99.100%, val_loss = 0.318, val_accuracy = 92.930% & LR: 0.0100\n",
      "epoch = 3 loss = 0.025, accuracy = 99.156%, val_loss = 0.302, val_accuracy = 93.090% & LR: 0.0100\n",
      "epoch = 4 loss = 0.023, accuracy = 99.226%, val_loss = 0.321, val_accuracy = 92.860% & LR: 0.0100\n",
      "epoch = 5 loss = 0.023, accuracy = 99.212%, val_loss = 0.308, val_accuracy = 93.110% & LR: 0.0100\n",
      "epoch = 6 loss = 0.022, accuracy = 99.250%, val_loss = 0.311, val_accuracy = 93.260% & LR: 0.0100\n",
      "epoch = 7 loss = 0.023, accuracy = 99.232%, val_loss = 0.318, val_accuracy = 92.970% & LR: 0.0100\n",
      "epoch = 8 loss = 0.021, accuracy = 99.304%, val_loss = 0.323, val_accuracy = 92.820% & LR: 0.0010\n",
      "epoch = 9 loss = 0.013, accuracy = 99.556%, val_loss = 0.282, val_accuracy = 93.710% & LR: 0.0010\n",
      "epoch = 10 loss = 0.009, accuracy = 99.712%, val_loss = 0.280, val_accuracy = 93.820% & LR: 0.0010\n",
      "epoch = 11 loss = 0.008, accuracy = 99.768%, val_loss = 0.278, val_accuracy = 93.770% & LR: 0.0010\n",
      "epoch = 12 loss = 0.007, accuracy = 99.770%, val_loss = 0.276, val_accuracy = 93.850% & LR: 0.0010\n",
      "epoch = 13 loss = 0.006, accuracy = 99.820%, val_loss = 0.284, val_accuracy = 93.800% & LR: 0.0010\n",
      "epoch = 14 loss = 0.006, accuracy = 99.836%, val_loss = 0.282, val_accuracy = 93.900% & LR: 0.0010\n",
      "epoch = 15 loss = 0.005, accuracy = 99.824%, val_loss = 0.284, val_accuracy = 93.890% & LR: 0.0001\n",
      "epoch = 16 loss = 0.005, accuracy = 99.844%, val_loss = 0.282, val_accuracy = 93.940% & LR: 0.0001\n",
      "epoch = 17 loss = 0.005, accuracy = 99.862%, val_loss = 0.283, val_accuracy = 93.850% & LR: 0.0001\n",
      "epoch = 18 loss = 0.005, accuracy = 99.870%, val_loss = 0.286, val_accuracy = 93.910% & LR: 0.0001\n",
      "epoch = 19 loss = 0.005, accuracy = 99.854%, val_loss = 0.287, val_accuracy = 93.920% & LR: 0.0001\n",
      "epoch = 20 loss = 0.004, accuracy = 99.880%, val_loss = 0.284, val_accuracy = 93.970% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 83.188% & val_accuracy = 93.970%\n",
      "\n",
      "Pruning and Finetuning 9/21\n",
      "Pruning...\n",
      "Global sparsity = 86.541% & val_accuracy = 92.270%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.332 & val_accuracy = 92.270%\n",
      "epoch = 1 loss = 0.036, accuracy = 98.726%, val_loss = 0.331, val_accuracy = 92.390% & LR: 0.0100\n",
      "epoch = 2 loss = 0.030, accuracy = 98.966%, val_loss = 0.307, val_accuracy = 92.820% & LR: 0.0100\n",
      "epoch = 3 loss = 0.028, accuracy = 99.060%, val_loss = 0.302, val_accuracy = 93.030% & LR: 0.0100\n",
      "epoch = 4 loss = 0.025, accuracy = 99.186%, val_loss = 0.347, val_accuracy = 92.220% & LR: 0.0100\n",
      "epoch = 5 loss = 0.025, accuracy = 99.108%, val_loss = 0.310, val_accuracy = 92.680% & LR: 0.0100\n",
      "epoch = 6 loss = 0.023, accuracy = 99.242%, val_loss = 0.311, val_accuracy = 92.830% & LR: 0.0100\n",
      "epoch = 7 loss = 0.023, accuracy = 99.238%, val_loss = 0.326, val_accuracy = 92.570% & LR: 0.0100\n",
      "epoch = 8 loss = 0.022, accuracy = 99.258%, val_loss = 0.310, val_accuracy = 92.790% & LR: 0.0010\n",
      "epoch = 9 loss = 0.014, accuracy = 99.556%, val_loss = 0.282, val_accuracy = 93.450% & LR: 0.0010\n",
      "epoch = 10 loss = 0.010, accuracy = 99.702%, val_loss = 0.277, val_accuracy = 93.710% & LR: 0.0010\n",
      "epoch = 11 loss = 0.007, accuracy = 99.776%, val_loss = 0.277, val_accuracy = 93.790% & LR: 0.0010\n",
      "epoch = 12 loss = 0.007, accuracy = 99.774%, val_loss = 0.280, val_accuracy = 93.520% & LR: 0.0010\n",
      "epoch = 13 loss = 0.006, accuracy = 99.796%, val_loss = 0.284, val_accuracy = 93.730% & LR: 0.0010\n",
      "epoch = 14 loss = 0.006, accuracy = 99.824%, val_loss = 0.282, val_accuracy = 93.770% & LR: 0.0010\n",
      "epoch = 15 loss = 0.006, accuracy = 99.828%, val_loss = 0.282, val_accuracy = 93.780% & LR: 0.0001\n",
      "epoch = 16 loss = 0.005, accuracy = 99.868%, val_loss = 0.285, val_accuracy = 93.830% & LR: 0.0001\n",
      "epoch = 17 loss = 0.005, accuracy = 99.846%, val_loss = 0.283, val_accuracy = 93.740% & LR: 0.0001\n",
      "epoch = 18 loss = 0.005, accuracy = 99.828%, val_loss = 0.285, val_accuracy = 93.730% & LR: 0.0001\n",
      "epoch = 19 loss = 0.005, accuracy = 99.862%, val_loss = 0.283, val_accuracy = 93.710% & LR: 0.0001\n",
      "epoch = 20 loss = 0.005, accuracy = 99.856%, val_loss = 0.285, val_accuracy = 93.820% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 86.541% & val_accuracy = 93.820%\n",
      "\n",
      "Pruning and Finetuning 10/21\n",
      "Pruning...\n",
      "Global sparsity = 89.223% & val_accuracy = 92.200%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.323 & val_accuracy = 92.200%\n",
      "epoch = 1 loss = 0.037, accuracy = 98.720%, val_loss = 0.324, val_accuracy = 92.420% & LR: 0.0100\n",
      "epoch = 2 loss = 0.032, accuracy = 98.896%, val_loss = 0.326, val_accuracy = 92.760% & LR: 0.0100\n",
      "epoch = 3 loss = 0.031, accuracy = 98.950%, val_loss = 0.324, val_accuracy = 92.640% & LR: 0.0100\n",
      "epoch = 4 loss = 0.026, accuracy = 99.108%, val_loss = 0.302, val_accuracy = 93.150% & LR: 0.0100\n",
      "epoch = 5 loss = 0.023, accuracy = 99.244%, val_loss = 0.307, val_accuracy = 92.720% & LR: 0.0100\n",
      "epoch = 6 loss = 0.021, accuracy = 99.242%, val_loss = 0.332, val_accuracy = 92.450% & LR: 0.0100\n",
      "epoch = 7 loss = 0.021, accuracy = 99.286%, val_loss = 0.337, val_accuracy = 92.840% & LR: 0.0100\n",
      "epoch = 8 loss = 0.023, accuracy = 99.188%, val_loss = 0.327, val_accuracy = 92.780% & LR: 0.0010\n",
      "epoch = 9 loss = 0.014, accuracy = 99.538%, val_loss = 0.289, val_accuracy = 93.430% & LR: 0.0010\n",
      "epoch = 10 loss = 0.010, accuracy = 99.680%, val_loss = 0.286, val_accuracy = 93.530% & LR: 0.0010\n",
      "epoch = 11 loss = 0.008, accuracy = 99.762%, val_loss = 0.287, val_accuracy = 93.580% & LR: 0.0010\n",
      "epoch = 12 loss = 0.007, accuracy = 99.762%, val_loss = 0.283, val_accuracy = 93.680% & LR: 0.0010\n",
      "epoch = 13 loss = 0.007, accuracy = 99.798%, val_loss = 0.288, val_accuracy = 93.600% & LR: 0.0010\n",
      "epoch = 14 loss = 0.006, accuracy = 99.806%, val_loss = 0.289, val_accuracy = 93.580% & LR: 0.0010\n",
      "epoch = 15 loss = 0.005, accuracy = 99.824%, val_loss = 0.287, val_accuracy = 93.740% & LR: 0.0001\n",
      "epoch = 16 loss = 0.005, accuracy = 99.842%, val_loss = 0.287, val_accuracy = 93.810% & LR: 0.0001\n",
      "epoch = 17 loss = 0.005, accuracy = 99.842%, val_loss = 0.286, val_accuracy = 93.760% & LR: 0.0001\n",
      "epoch = 18 loss = 0.005, accuracy = 99.840%, val_loss = 0.286, val_accuracy = 93.720% & LR: 0.0001\n",
      "epoch = 19 loss = 0.005, accuracy = 99.818%, val_loss = 0.288, val_accuracy = 93.700% & LR: 0.0001\n",
      "epoch = 20 loss = 0.005, accuracy = 99.852%, val_loss = 0.285, val_accuracy = 93.770% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 89.223% & val_accuracy = 93.770%\n",
      "\n",
      "Pruning and Finetuning 11/21\n",
      "Pruning...\n",
      "Global sparsity = 91.368% & val_accuracy = 91.790%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.325 & val_accuracy = 91.790%\n",
      "epoch = 1 loss = 0.036, accuracy = 98.790%, val_loss = 0.342, val_accuracy = 92.190% & LR: 0.0100\n",
      "epoch = 2 loss = 0.034, accuracy = 98.828%, val_loss = 0.316, val_accuracy = 92.360% & LR: 0.0100\n",
      "epoch = 3 loss = 0.030, accuracy = 99.002%, val_loss = 0.313, val_accuracy = 92.550% & LR: 0.0100\n",
      "epoch = 4 loss = 0.022, accuracy = 99.272%, val_loss = 0.349, val_accuracy = 92.360% & LR: 0.0100\n",
      "epoch = 5 loss = 0.025, accuracy = 99.140%, val_loss = 0.386, val_accuracy = 91.670% & LR: 0.0100\n",
      "epoch = 6 loss = 0.026, accuracy = 99.118%, val_loss = 0.328, val_accuracy = 92.540% & LR: 0.0100\n",
      "epoch = 7 loss = 0.026, accuracy = 99.124%, val_loss = 0.359, val_accuracy = 92.410% & LR: 0.0100\n",
      "epoch = 8 loss = 0.025, accuracy = 99.138%, val_loss = 0.326, val_accuracy = 92.700% & LR: 0.0010\n",
      "epoch = 9 loss = 0.016, accuracy = 99.510%, val_loss = 0.295, val_accuracy = 93.240% & LR: 0.0010\n",
      "epoch = 10 loss = 0.010, accuracy = 99.652%, val_loss = 0.290, val_accuracy = 93.460% & LR: 0.0010\n",
      "epoch = 11 loss = 0.008, accuracy = 99.716%, val_loss = 0.291, val_accuracy = 93.580% & LR: 0.0010\n",
      "epoch = 12 loss = 0.007, accuracy = 99.786%, val_loss = 0.292, val_accuracy = 93.600% & LR: 0.0010\n",
      "epoch = 13 loss = 0.007, accuracy = 99.814%, val_loss = 0.292, val_accuracy = 93.730% & LR: 0.0010\n",
      "epoch = 14 loss = 0.007, accuracy = 99.800%, val_loss = 0.294, val_accuracy = 93.650% & LR: 0.0010\n",
      "epoch = 15 loss = 0.006, accuracy = 99.798%, val_loss = 0.296, val_accuracy = 93.760% & LR: 0.0001\n",
      "epoch = 16 loss = 0.006, accuracy = 99.798%, val_loss = 0.295, val_accuracy = 93.870% & LR: 0.0001\n",
      "epoch = 17 loss = 0.006, accuracy = 99.826%, val_loss = 0.297, val_accuracy = 93.760% & LR: 0.0001\n",
      "epoch = 18 loss = 0.005, accuracy = 99.850%, val_loss = 0.294, val_accuracy = 93.780% & LR: 0.0001\n",
      "epoch = 19 loss = 0.006, accuracy = 99.820%, val_loss = 0.296, val_accuracy = 93.740% & LR: 0.0001\n",
      "epoch = 20 loss = 0.006, accuracy = 99.820%, val_loss = 0.294, val_accuracy = 93.800% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 91.368% & val_accuracy = 93.800%\n",
      "\n",
      "Pruning and Finetuning 12/21\n",
      "Pruning...\n",
      "Global sparsity = 93.084% & val_accuracy = 92.440%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.315 & val_accuracy = 92.440%\n",
      "epoch = 1 loss = 0.040, accuracy = 98.650%, val_loss = 0.343, val_accuracy = 92.050% & LR: 0.0100\n",
      "epoch = 2 loss = 0.037, accuracy = 98.676%, val_loss = 0.330, val_accuracy = 92.170% & LR: 0.0100\n",
      "epoch = 3 loss = 0.032, accuracy = 98.900%, val_loss = 0.321, val_accuracy = 92.690% & LR: 0.0100\n",
      "epoch = 4 loss = 0.030, accuracy = 98.996%, val_loss = 0.332, val_accuracy = 92.220% & LR: 0.0100\n",
      "epoch = 5 loss = 0.026, accuracy = 99.098%, val_loss = 0.318, val_accuracy = 92.640% & LR: 0.0100\n",
      "epoch = 6 loss = 0.028, accuracy = 99.022%, val_loss = 0.338, val_accuracy = 92.550% & LR: 0.0100\n",
      "epoch = 7 loss = 0.028, accuracy = 99.082%, val_loss = 0.323, val_accuracy = 92.780% & LR: 0.0100\n",
      "epoch = 8 loss = 0.025, accuracy = 99.106%, val_loss = 0.344, val_accuracy = 92.340% & LR: 0.0010\n",
      "epoch = 9 loss = 0.017, accuracy = 99.406%, val_loss = 0.296, val_accuracy = 93.370% & LR: 0.0010\n",
      "epoch = 10 loss = 0.013, accuracy = 99.560%, val_loss = 0.286, val_accuracy = 93.580% & LR: 0.0010\n",
      "epoch = 11 loss = 0.009, accuracy = 99.726%, val_loss = 0.282, val_accuracy = 93.810% & LR: 0.0010\n",
      "epoch = 12 loss = 0.009, accuracy = 99.730%, val_loss = 0.284, val_accuracy = 93.670% & LR: 0.0010\n",
      "epoch = 13 loss = 0.008, accuracy = 99.752%, val_loss = 0.284, val_accuracy = 93.770% & LR: 0.0010\n",
      "epoch = 14 loss = 0.007, accuracy = 99.790%, val_loss = 0.281, val_accuracy = 93.760% & LR: 0.0010\n",
      "epoch = 15 loss = 0.006, accuracy = 99.782%, val_loss = 0.280, val_accuracy = 93.880% & LR: 0.0001\n",
      "epoch = 16 loss = 0.006, accuracy = 99.808%, val_loss = 0.281, val_accuracy = 93.830% & LR: 0.0001\n",
      "epoch = 17 loss = 0.006, accuracy = 99.828%, val_loss = 0.280, val_accuracy = 93.830% & LR: 0.0001\n",
      "epoch = 18 loss = 0.007, accuracy = 99.792%, val_loss = 0.281, val_accuracy = 93.950% & LR: 0.0001\n",
      "epoch = 19 loss = 0.006, accuracy = 99.848%, val_loss = 0.280, val_accuracy = 93.910% & LR: 0.0001\n",
      "epoch = 20 loss = 0.006, accuracy = 99.814%, val_loss = 0.282, val_accuracy = 93.830% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 93.084% & val_accuracy = 93.830%\n",
      "\n",
      "Pruning and Finetuning 13/21\n",
      "Pruning...\n",
      "Global sparsity = 94.457% & val_accuracy = 91.760%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.303 & val_accuracy = 91.760%\n",
      "epoch = 1 loss = 0.039, accuracy = 98.656%, val_loss = 0.331, val_accuracy = 92.010% & LR: 0.0100\n",
      "epoch = 2 loss = 0.040, accuracy = 98.620%, val_loss = 0.312, val_accuracy = 92.380% & LR: 0.0100\n",
      "epoch = 3 loss = 0.032, accuracy = 98.866%, val_loss = 0.334, val_accuracy = 92.260% & LR: 0.0100\n",
      "epoch = 4 loss = 0.029, accuracy = 98.974%, val_loss = 0.318, val_accuracy = 92.730% & LR: 0.0100\n",
      "epoch = 5 loss = 0.031, accuracy = 98.906%, val_loss = 0.340, val_accuracy = 92.120% & LR: 0.0100\n",
      "epoch = 6 loss = 0.031, accuracy = 98.936%, val_loss = 0.337, val_accuracy = 92.130% & LR: 0.0100\n",
      "epoch = 7 loss = 0.028, accuracy = 99.054%, val_loss = 0.323, val_accuracy = 92.980% & LR: 0.0100\n",
      "epoch = 8 loss = 0.028, accuracy = 99.020%, val_loss = 0.349, val_accuracy = 91.980% & LR: 0.0010\n",
      "epoch = 9 loss = 0.019, accuracy = 99.344%, val_loss = 0.296, val_accuracy = 93.190% & LR: 0.0010\n",
      "epoch = 10 loss = 0.013, accuracy = 99.602%, val_loss = 0.288, val_accuracy = 93.330% & LR: 0.0010\n",
      "epoch = 11 loss = 0.010, accuracy = 99.684%, val_loss = 0.285, val_accuracy = 93.350% & LR: 0.0010\n",
      "epoch = 12 loss = 0.010, accuracy = 99.674%, val_loss = 0.285, val_accuracy = 93.430% & LR: 0.0010\n",
      "epoch = 13 loss = 0.008, accuracy = 99.732%, val_loss = 0.282, val_accuracy = 93.500% & LR: 0.0010\n",
      "epoch = 14 loss = 0.008, accuracy = 99.820%, val_loss = 0.282, val_accuracy = 93.660% & LR: 0.0010\n",
      "epoch = 15 loss = 0.007, accuracy = 99.782%, val_loss = 0.281, val_accuracy = 93.550% & LR: 0.0001\n",
      "epoch = 16 loss = 0.007, accuracy = 99.794%, val_loss = 0.281, val_accuracy = 93.620% & LR: 0.0001\n",
      "epoch = 17 loss = 0.006, accuracy = 99.836%, val_loss = 0.280, val_accuracy = 93.610% & LR: 0.0001\n",
      "epoch = 18 loss = 0.007, accuracy = 99.808%, val_loss = 0.282, val_accuracy = 93.540% & LR: 0.0001\n",
      "epoch = 19 loss = 0.006, accuracy = 99.794%, val_loss = 0.281, val_accuracy = 93.540% & LR: 0.0001\n",
      "epoch = 20 loss = 0.006, accuracy = 99.830%, val_loss = 0.284, val_accuracy = 93.590% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 94.457% & val_accuracy = 93.590%\n",
      "\n",
      "Pruning and Finetuning 14/21\n",
      "Pruning...\n",
      "Global sparsity = 95.554% & val_accuracy = 91.600%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.300 & val_accuracy = 91.600%\n",
      "epoch = 1 loss = 0.047, accuracy = 98.388%, val_loss = 0.337, val_accuracy = 91.990% & LR: 0.0100\n",
      "epoch = 2 loss = 0.039, accuracy = 98.626%, val_loss = 0.311, val_accuracy = 92.370% & LR: 0.0100\n",
      "epoch = 3 loss = 0.039, accuracy = 98.642%, val_loss = 0.343, val_accuracy = 92.040% & LR: 0.0100\n",
      "epoch = 4 loss = 0.037, accuracy = 98.720%, val_loss = 0.334, val_accuracy = 92.070% & LR: 0.0100\n",
      "epoch = 5 loss = 0.035, accuracy = 98.796%, val_loss = 0.308, val_accuracy = 92.720% & LR: 0.0100\n",
      "epoch = 6 loss = 0.031, accuracy = 98.898%, val_loss = 0.323, val_accuracy = 92.500% & LR: 0.0100\n",
      "epoch = 7 loss = 0.031, accuracy = 98.914%, val_loss = 0.326, val_accuracy = 92.180% & LR: 0.0100\n",
      "epoch = 8 loss = 0.030, accuracy = 98.992%, val_loss = 0.310, val_accuracy = 92.700% & LR: 0.0010\n",
      "epoch = 9 loss = 0.020, accuracy = 99.304%, val_loss = 0.273, val_accuracy = 93.350% & LR: 0.0010\n",
      "epoch = 10 loss = 0.014, accuracy = 99.548%, val_loss = 0.271, val_accuracy = 93.640% & LR: 0.0010\n",
      "epoch = 11 loss = 0.012, accuracy = 99.654%, val_loss = 0.267, val_accuracy = 93.600% & LR: 0.0010\n",
      "epoch = 12 loss = 0.010, accuracy = 99.682%, val_loss = 0.267, val_accuracy = 93.630% & LR: 0.0010\n",
      "epoch = 13 loss = 0.010, accuracy = 99.680%, val_loss = 0.265, val_accuracy = 93.680% & LR: 0.0010\n",
      "epoch = 14 loss = 0.009, accuracy = 99.744%, val_loss = 0.269, val_accuracy = 93.720% & LR: 0.0010\n",
      "epoch = 15 loss = 0.009, accuracy = 99.758%, val_loss = 0.267, val_accuracy = 93.740% & LR: 0.0001\n",
      "epoch = 16 loss = 0.008, accuracy = 99.752%, val_loss = 0.268, val_accuracy = 93.760% & LR: 0.0001\n",
      "epoch = 17 loss = 0.007, accuracy = 99.770%, val_loss = 0.267, val_accuracy = 93.750% & LR: 0.0001\n",
      "epoch = 18 loss = 0.007, accuracy = 99.782%, val_loss = 0.268, val_accuracy = 93.790% & LR: 0.0001\n",
      "epoch = 19 loss = 0.008, accuracy = 99.788%, val_loss = 0.270, val_accuracy = 93.700% & LR: 0.0001\n",
      "epoch = 20 loss = 0.008, accuracy = 99.756%, val_loss = 0.265, val_accuracy = 93.830% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 95.554% & val_accuracy = 93.830%\n",
      "\n",
      "Pruning and Finetuning 15/21\n",
      "Pruning...\n",
      "Global sparsity = 96.431% & val_accuracy = 91.380%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.312 & val_accuracy = 91.380%\n",
      "epoch = 1 loss = 0.050, accuracy = 98.268%, val_loss = 0.338, val_accuracy = 91.650% & LR: 0.0100\n",
      "epoch = 2 loss = 0.049, accuracy = 98.236%, val_loss = 0.307, val_accuracy = 92.170% & LR: 0.0100\n",
      "epoch = 3 loss = 0.041, accuracy = 98.584%, val_loss = 0.322, val_accuracy = 92.110% & LR: 0.0100\n",
      "epoch = 4 loss = 0.040, accuracy = 98.596%, val_loss = 0.320, val_accuracy = 92.220% & LR: 0.0100\n",
      "epoch = 5 loss = 0.039, accuracy = 98.608%, val_loss = 0.332, val_accuracy = 91.690% & LR: 0.0100\n",
      "epoch = 6 loss = 0.037, accuracy = 98.686%, val_loss = 0.321, val_accuracy = 92.320% & LR: 0.0100\n",
      "epoch = 7 loss = 0.037, accuracy = 98.738%, val_loss = 0.306, val_accuracy = 92.560% & LR: 0.0100\n",
      "epoch = 8 loss = 0.035, accuracy = 98.742%, val_loss = 0.296, val_accuracy = 92.780% & LR: 0.0010\n",
      "epoch = 9 loss = 0.023, accuracy = 99.234%, val_loss = 0.267, val_accuracy = 93.440% & LR: 0.0010\n",
      "epoch = 10 loss = 0.017, accuracy = 99.446%, val_loss = 0.260, val_accuracy = 93.680% & LR: 0.0010\n",
      "epoch = 11 loss = 0.015, accuracy = 99.526%, val_loss = 0.259, val_accuracy = 93.770% & LR: 0.0010\n",
      "epoch = 12 loss = 0.013, accuracy = 99.566%, val_loss = 0.258, val_accuracy = 93.890% & LR: 0.0010\n",
      "epoch = 13 loss = 0.012, accuracy = 99.636%, val_loss = 0.261, val_accuracy = 93.840% & LR: 0.0010\n",
      "epoch = 14 loss = 0.011, accuracy = 99.620%, val_loss = 0.262, val_accuracy = 93.790% & LR: 0.0010\n",
      "epoch = 15 loss = 0.011, accuracy = 99.664%, val_loss = 0.261, val_accuracy = 94.020% & LR: 0.0001\n",
      "epoch = 16 loss = 0.010, accuracy = 99.708%, val_loss = 0.260, val_accuracy = 93.920% & LR: 0.0001\n",
      "epoch = 17 loss = 0.009, accuracy = 99.752%, val_loss = 0.260, val_accuracy = 94.000% & LR: 0.0001\n",
      "epoch = 18 loss = 0.010, accuracy = 99.728%, val_loss = 0.262, val_accuracy = 93.930% & LR: 0.0001\n",
      "epoch = 19 loss = 0.009, accuracy = 99.730%, val_loss = 0.261, val_accuracy = 93.960% & LR: 0.0001\n",
      "epoch = 20 loss = 0.010, accuracy = 99.688%, val_loss = 0.260, val_accuracy = 94.040% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 96.431% & val_accuracy = 94.040%\n",
      "\n",
      "Pruning and Finetuning 16/21\n",
      "Pruning...\n",
      "Global sparsity = 97.133% & val_accuracy = 90.790%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.318 & val_accuracy = 90.790%\n",
      "epoch = 1 loss = 0.057, accuracy = 98.012%, val_loss = 0.315, val_accuracy = 91.950% & LR: 0.0100\n",
      "epoch = 2 loss = 0.054, accuracy = 98.084%, val_loss = 0.304, val_accuracy = 92.080% & LR: 0.0100\n",
      "epoch = 3 loss = 0.046, accuracy = 98.398%, val_loss = 0.303, val_accuracy = 92.230% & LR: 0.0100\n",
      "epoch = 4 loss = 0.044, accuracy = 98.538%, val_loss = 0.302, val_accuracy = 92.450% & LR: 0.0100\n",
      "epoch = 5 loss = 0.041, accuracy = 98.600%, val_loss = 0.323, val_accuracy = 92.400% & LR: 0.0100\n",
      "epoch = 6 loss = 0.038, accuracy = 98.666%, val_loss = 0.297, val_accuracy = 92.550% & LR: 0.0100\n",
      "epoch = 7 loss = 0.039, accuracy = 98.688%, val_loss = 0.318, val_accuracy = 92.160% & LR: 0.0100\n",
      "epoch = 8 loss = 0.037, accuracy = 98.720%, val_loss = 0.309, val_accuracy = 92.200% & LR: 0.0010\n",
      "epoch = 9 loss = 0.024, accuracy = 99.142%, val_loss = 0.268, val_accuracy = 93.410% & LR: 0.0010\n",
      "epoch = 10 loss = 0.018, accuracy = 99.428%, val_loss = 0.264, val_accuracy = 93.600% & LR: 0.0010\n",
      "epoch = 11 loss = 0.016, accuracy = 99.486%, val_loss = 0.263, val_accuracy = 93.610% & LR: 0.0010\n",
      "epoch = 12 loss = 0.015, accuracy = 99.528%, val_loss = 0.264, val_accuracy = 93.530% & LR: 0.0010\n",
      "epoch = 13 loss = 0.013, accuracy = 99.626%, val_loss = 0.265, val_accuracy = 93.620% & LR: 0.0010\n",
      "epoch = 14 loss = 0.012, accuracy = 99.644%, val_loss = 0.264, val_accuracy = 93.670% & LR: 0.0010\n",
      "epoch = 15 loss = 0.011, accuracy = 99.652%, val_loss = 0.261, val_accuracy = 93.740% & LR: 0.0001\n",
      "epoch = 16 loss = 0.011, accuracy = 99.684%, val_loss = 0.261, val_accuracy = 93.670% & LR: 0.0001\n",
      "epoch = 17 loss = 0.011, accuracy = 99.684%, val_loss = 0.259, val_accuracy = 93.720% & LR: 0.0001\n",
      "epoch = 18 loss = 0.010, accuracy = 99.664%, val_loss = 0.260, val_accuracy = 93.670% & LR: 0.0001\n",
      "epoch = 19 loss = 0.011, accuracy = 99.702%, val_loss = 0.260, val_accuracy = 93.750% & LR: 0.0001\n",
      "epoch = 20 loss = 0.011, accuracy = 99.666%, val_loss = 0.260, val_accuracy = 93.840% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 97.133% & val_accuracy = 93.840%\n",
      "\n",
      "Pruning and Finetuning 17/21\n",
      "Pruning...\n",
      "Global sparsity = 97.694% & val_accuracy = 88.790%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.410 & val_accuracy = 88.790%\n",
      "epoch = 1 loss = 0.063, accuracy = 97.812%, val_loss = 0.312, val_accuracy = 91.620% & LR: 0.0100\n",
      "epoch = 2 loss = 0.058, accuracy = 97.960%, val_loss = 0.315, val_accuracy = 91.820% & LR: 0.0100\n",
      "epoch = 3 loss = 0.049, accuracy = 98.350%, val_loss = 0.294, val_accuracy = 92.510% & LR: 0.0100\n",
      "epoch = 4 loss = 0.048, accuracy = 98.360%, val_loss = 0.306, val_accuracy = 92.120% & LR: 0.0100\n",
      "epoch = 5 loss = 0.049, accuracy = 98.296%, val_loss = 0.311, val_accuracy = 91.980% & LR: 0.0100\n",
      "epoch = 6 loss = 0.043, accuracy = 98.474%, val_loss = 0.338, val_accuracy = 91.890% & LR: 0.0100\n",
      "epoch = 7 loss = 0.046, accuracy = 98.378%, val_loss = 0.317, val_accuracy = 91.760% & LR: 0.0100\n",
      "epoch = 8 loss = 0.042, accuracy = 98.518%, val_loss = 0.312, val_accuracy = 91.830% & LR: 0.0010\n",
      "epoch = 9 loss = 0.030, accuracy = 99.002%, val_loss = 0.266, val_accuracy = 92.960% & LR: 0.0010\n",
      "epoch = 10 loss = 0.022, accuracy = 99.270%, val_loss = 0.260, val_accuracy = 93.280% & LR: 0.0010\n",
      "epoch = 11 loss = 0.017, accuracy = 99.462%, val_loss = 0.258, val_accuracy = 93.430% & LR: 0.0010\n",
      "epoch = 12 loss = 0.017, accuracy = 99.446%, val_loss = 0.257, val_accuracy = 93.590% & LR: 0.0010\n",
      "epoch = 13 loss = 0.016, accuracy = 99.494%, val_loss = 0.259, val_accuracy = 93.630% & LR: 0.0010\n",
      "epoch = 14 loss = 0.014, accuracy = 99.580%, val_loss = 0.257, val_accuracy = 93.740% & LR: 0.0010\n",
      "epoch = 15 loss = 0.014, accuracy = 99.592%, val_loss = 0.257, val_accuracy = 93.790% & LR: 0.0001\n",
      "epoch = 16 loss = 0.014, accuracy = 99.616%, val_loss = 0.260, val_accuracy = 93.660% & LR: 0.0001\n",
      "epoch = 17 loss = 0.013, accuracy = 99.642%, val_loss = 0.254, val_accuracy = 93.710% & LR: 0.0001\n",
      "epoch = 18 loss = 0.014, accuracy = 99.618%, val_loss = 0.257, val_accuracy = 93.840% & LR: 0.0001\n",
      "epoch = 19 loss = 0.013, accuracy = 99.614%, val_loss = 0.258, val_accuracy = 93.740% & LR: 0.0001\n",
      "epoch = 20 loss = 0.014, accuracy = 99.600%, val_loss = 0.256, val_accuracy = 93.860% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 97.694% & val_accuracy = 93.860%\n",
      "\n",
      "Pruning and Finetuning 18/21\n",
      "Pruning...\n",
      "Global sparsity = 98.143% & val_accuracy = 88.970%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.360 & val_accuracy = 88.970%\n",
      "epoch = 1 loss = 0.068, accuracy = 97.588%, val_loss = 0.310, val_accuracy = 91.850% & LR: 0.0100\n",
      "epoch = 2 loss = 0.067, accuracy = 97.696%, val_loss = 0.301, val_accuracy = 92.060% & LR: 0.0100\n",
      "epoch = 3 loss = 0.061, accuracy = 97.848%, val_loss = 0.304, val_accuracy = 92.010% & LR: 0.0100\n",
      "epoch = 4 loss = 0.058, accuracy = 97.968%, val_loss = 0.345, val_accuracy = 91.290% & LR: 0.0100\n",
      "epoch = 5 loss = 0.052, accuracy = 98.210%, val_loss = 0.312, val_accuracy = 91.970% & LR: 0.0100\n",
      "epoch = 6 loss = 0.053, accuracy = 98.126%, val_loss = 0.312, val_accuracy = 91.950% & LR: 0.0100\n",
      "epoch = 7 loss = 0.051, accuracy = 98.232%, val_loss = 0.321, val_accuracy = 91.980% & LR: 0.0100\n",
      "epoch = 8 loss = 0.047, accuracy = 98.326%, val_loss = 0.309, val_accuracy = 92.030% & LR: 0.0010\n",
      "epoch = 9 loss = 0.032, accuracy = 98.910%, val_loss = 0.278, val_accuracy = 92.850% & LR: 0.0010\n",
      "epoch = 10 loss = 0.026, accuracy = 99.130%, val_loss = 0.270, val_accuracy = 93.000% & LR: 0.0010\n",
      "epoch = 11 loss = 0.022, accuracy = 99.308%, val_loss = 0.267, val_accuracy = 93.090% & LR: 0.0010\n",
      "epoch = 12 loss = 0.020, accuracy = 99.352%, val_loss = 0.269, val_accuracy = 93.050% & LR: 0.0010\n",
      "epoch = 13 loss = 0.019, accuracy = 99.376%, val_loss = 0.268, val_accuracy = 93.290% & LR: 0.0010\n",
      "epoch = 14 loss = 0.018, accuracy = 99.466%, val_loss = 0.268, val_accuracy = 93.270% & LR: 0.0010\n",
      "epoch = 15 loss = 0.017, accuracy = 99.488%, val_loss = 0.270, val_accuracy = 93.170% & LR: 0.0001\n",
      "epoch = 16 loss = 0.015, accuracy = 99.562%, val_loss = 0.267, val_accuracy = 93.200% & LR: 0.0001\n",
      "epoch = 17 loss = 0.015, accuracy = 99.526%, val_loss = 0.271, val_accuracy = 93.210% & LR: 0.0001\n",
      "epoch = 18 loss = 0.015, accuracy = 99.532%, val_loss = 0.271, val_accuracy = 93.130% & LR: 0.0001\n",
      "epoch = 19 loss = 0.015, accuracy = 99.540%, val_loss = 0.271, val_accuracy = 93.080% & LR: 0.0001\n",
      "epoch = 20 loss = 0.014, accuracy = 99.602%, val_loss = 0.269, val_accuracy = 93.240% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 98.143% & val_accuracy = 93.240%\n",
      "\n",
      "Pruning and Finetuning 19/21\n",
      "Pruning...\n",
      "Global sparsity = 98.501% & val_accuracy = 88.920%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.362 & val_accuracy = 88.920%\n",
      "epoch = 1 loss = 0.077, accuracy = 97.308%, val_loss = 0.362, val_accuracy = 90.870% & LR: 0.0100\n",
      "epoch = 2 loss = 0.083, accuracy = 97.186%, val_loss = 0.319, val_accuracy = 91.160% & LR: 0.0100\n",
      "epoch = 3 loss = 0.071, accuracy = 97.546%, val_loss = 0.303, val_accuracy = 91.630% & LR: 0.0100\n",
      "epoch = 4 loss = 0.066, accuracy = 97.728%, val_loss = 0.302, val_accuracy = 91.700% & LR: 0.0100\n",
      "epoch = 5 loss = 0.063, accuracy = 97.758%, val_loss = 0.324, val_accuracy = 91.790% & LR: 0.0100\n",
      "epoch = 6 loss = 0.060, accuracy = 97.894%, val_loss = 0.310, val_accuracy = 91.910% & LR: 0.0100\n",
      "epoch = 7 loss = 0.057, accuracy = 98.044%, val_loss = 0.308, val_accuracy = 91.760% & LR: 0.0100\n",
      "epoch = 8 loss = 0.055, accuracy = 98.124%, val_loss = 0.316, val_accuracy = 91.700% & LR: 0.0010\n",
      "epoch = 9 loss = 0.038, accuracy = 98.720%, val_loss = 0.270, val_accuracy = 92.870% & LR: 0.0010\n",
      "epoch = 10 loss = 0.030, accuracy = 99.012%, val_loss = 0.264, val_accuracy = 92.990% & LR: 0.0010\n",
      "epoch = 11 loss = 0.027, accuracy = 99.160%, val_loss = 0.262, val_accuracy = 93.170% & LR: 0.0010\n",
      "epoch = 12 loss = 0.026, accuracy = 99.164%, val_loss = 0.263, val_accuracy = 93.110% & LR: 0.0010\n",
      "epoch = 13 loss = 0.023, accuracy = 99.304%, val_loss = 0.265, val_accuracy = 93.250% & LR: 0.0010\n",
      "epoch = 14 loss = 0.020, accuracy = 99.408%, val_loss = 0.260, val_accuracy = 93.230% & LR: 0.0010\n",
      "epoch = 15 loss = 0.021, accuracy = 99.346%, val_loss = 0.265, val_accuracy = 93.190% & LR: 0.0001\n",
      "epoch = 16 loss = 0.020, accuracy = 99.438%, val_loss = 0.263, val_accuracy = 93.300% & LR: 0.0001\n",
      "epoch = 17 loss = 0.019, accuracy = 99.468%, val_loss = 0.263, val_accuracy = 93.120% & LR: 0.0001\n",
      "epoch = 18 loss = 0.020, accuracy = 99.380%, val_loss = 0.262, val_accuracy = 93.220% & LR: 0.0001\n",
      "epoch = 19 loss = 0.018, accuracy = 99.468%, val_loss = 0.262, val_accuracy = 93.280% & LR: 0.0001\n",
      "epoch = 20 loss = 0.019, accuracy = 99.432%, val_loss = 0.260, val_accuracy = 93.280% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 98.501% & val_accuracy = 93.280%\n",
      "\n",
      "Pruning and Finetuning 20/21\n",
      "Pruning...\n",
      "Global sparsity = 98.787% & val_accuracy = 84.970%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.507 & val_accuracy = 84.970%\n",
      "epoch = 1 loss = 0.092, accuracy = 96.800%, val_loss = 0.331, val_accuracy = 90.910% & LR: 0.0100\n",
      "epoch = 2 loss = 0.089, accuracy = 96.908%, val_loss = 0.342, val_accuracy = 90.710% & LR: 0.0100\n",
      "epoch = 3 loss = 0.083, accuracy = 97.162%, val_loss = 0.321, val_accuracy = 91.380% & LR: 0.0100\n",
      "epoch = 4 loss = 0.077, accuracy = 97.316%, val_loss = 0.336, val_accuracy = 90.980% & LR: 0.0100\n",
      "epoch = 5 loss = 0.076, accuracy = 97.360%, val_loss = 0.326, val_accuracy = 91.170% & LR: 0.0100\n",
      "epoch = 6 loss = 0.071, accuracy = 97.510%, val_loss = 0.320, val_accuracy = 91.360% & LR: 0.0100\n",
      "epoch = 7 loss = 0.069, accuracy = 97.560%, val_loss = 0.320, val_accuracy = 91.420% & LR: 0.0100\n",
      "epoch = 8 loss = 0.071, accuracy = 97.598%, val_loss = 0.306, val_accuracy = 91.800% & LR: 0.0010\n",
      "epoch = 9 loss = 0.046, accuracy = 98.432%, val_loss = 0.266, val_accuracy = 92.840% & LR: 0.0010\n",
      "epoch = 10 loss = 0.039, accuracy = 98.762%, val_loss = 0.269, val_accuracy = 92.990% & LR: 0.0010\n",
      "epoch = 11 loss = 0.033, accuracy = 98.920%, val_loss = 0.264, val_accuracy = 93.060% & LR: 0.0010\n",
      "epoch = 12 loss = 0.033, accuracy = 98.932%, val_loss = 0.264, val_accuracy = 92.920% & LR: 0.0010\n",
      "epoch = 13 loss = 0.029, accuracy = 99.044%, val_loss = 0.267, val_accuracy = 93.030% & LR: 0.0010\n",
      "epoch = 14 loss = 0.029, accuracy = 99.088%, val_loss = 0.265, val_accuracy = 93.110% & LR: 0.0010\n",
      "epoch = 15 loss = 0.027, accuracy = 99.152%, val_loss = 0.267, val_accuracy = 93.230% & LR: 0.0001\n",
      "epoch = 16 loss = 0.026, accuracy = 99.202%, val_loss = 0.267, val_accuracy = 93.210% & LR: 0.0001\n",
      "epoch = 17 loss = 0.025, accuracy = 99.266%, val_loss = 0.268, val_accuracy = 93.230% & LR: 0.0001\n",
      "epoch = 18 loss = 0.025, accuracy = 99.288%, val_loss = 0.271, val_accuracy = 93.200% & LR: 0.0001\n",
      "epoch = 19 loss = 0.027, accuracy = 99.158%, val_loss = 0.266, val_accuracy = 93.350% & LR: 0.0001\n",
      "epoch = 20 loss = 0.025, accuracy = 99.216%, val_loss = 0.266, val_accuracy = 93.190% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 98.787% & val_accuracy = 93.190%\n",
      "\n",
      "Pruning and Finetuning 21/21\n",
      "Pruning...\n",
      "Global sparsity = 99.016% & val_accuracy = 83.390%\n",
      "\n",
      "Fine-tuning...\n",
      "Pre fine-tuning: val_loss = 0.550 & val_accuracy = 83.390%\n",
      "epoch = 1 loss = 0.109, accuracy = 96.158%, val_loss = 0.325, val_accuracy = 91.010% & LR: 0.0100\n",
      "epoch = 2 loss = 0.101, accuracy = 96.434%, val_loss = 0.299, val_accuracy = 91.520% & LR: 0.0100\n",
      "epoch = 3 loss = 0.090, accuracy = 96.880%, val_loss = 0.307, val_accuracy = 91.220% & LR: 0.0100\n",
      "epoch = 4 loss = 0.091, accuracy = 96.776%, val_loss = 0.317, val_accuracy = 91.370% & LR: 0.0100\n",
      "epoch = 5 loss = 0.088, accuracy = 96.898%, val_loss = 0.319, val_accuracy = 91.070% & LR: 0.0100\n",
      "epoch = 6 loss = 0.083, accuracy = 97.024%, val_loss = 0.314, val_accuracy = 91.490% & LR: 0.0100\n",
      "epoch = 7 loss = 0.086, accuracy = 96.956%, val_loss = 0.315, val_accuracy = 91.260% & LR: 0.0100\n",
      "epoch = 8 loss = 0.077, accuracy = 97.288%, val_loss = 0.304, val_accuracy = 91.680% & LR: 0.0010\n",
      "epoch = 9 loss = 0.056, accuracy = 98.120%, val_loss = 0.268, val_accuracy = 92.760% & LR: 0.0010\n",
      "epoch = 10 loss = 0.046, accuracy = 98.454%, val_loss = 0.265, val_accuracy = 92.720% & LR: 0.0010\n",
      "epoch = 11 loss = 0.042, accuracy = 98.586%, val_loss = 0.267, val_accuracy = 92.900% & LR: 0.0010\n",
      "epoch = 12 loss = 0.039, accuracy = 98.724%, val_loss = 0.263, val_accuracy = 92.920% & LR: 0.0010\n",
      "epoch = 13 loss = 0.037, accuracy = 98.830%, val_loss = 0.263, val_accuracy = 92.860% & LR: 0.0010\n",
      "epoch = 14 loss = 0.034, accuracy = 98.938%, val_loss = 0.265, val_accuracy = 92.960% & LR: 0.0010\n",
      "epoch = 15 loss = 0.034, accuracy = 98.926%, val_loss = 0.266, val_accuracy = 92.950% & LR: 0.0001\n",
      "epoch = 16 loss = 0.033, accuracy = 98.972%, val_loss = 0.267, val_accuracy = 92.940% & LR: 0.0001\n",
      "epoch = 17 loss = 0.031, accuracy = 99.074%, val_loss = 0.265, val_accuracy = 93.120% & LR: 0.0001\n",
      "epoch = 18 loss = 0.030, accuracy = 99.072%, val_loss = 0.265, val_accuracy = 92.960% & LR: 0.0001\n",
      "epoch = 19 loss = 0.032, accuracy = 98.990%, val_loss = 0.265, val_accuracy = 93.120% & LR: 0.0001\n",
      "epoch = 20 loss = 0.031, accuracy = 99.040%, val_loss = 0.267, val_accuracy = 92.940% & LR: 0.0001\n",
      "Post fine-tuning: Global sparsity = 99.016% & val_accuracy = 92.940%\n",
      "Global sparsity = 0.991 & val_accuracy = 0.929\n"
     ]
    }
   ],
   "source": [
    "# Create a deep copy of the pre-trained model-\n",
    "pruned_model = copy.deepcopy(trained_model)\n",
    "\n",
    "\n",
    "# Prune and fine-tune trained model-\n",
    "'''\n",
    "num_iterations - number of pruning iterations/rounds\n",
    "num_epochs_per_iteration - number of fine-tuning rounds\n",
    "'''\n",
    "pruned_model = iterative_pruning_finetuning(\n",
    "        model = pruned_model, train_loader = train_loader,\n",
    "        test_loader = test_loader, device = device,\n",
    "        learning_rate = learning_rate, learning_rate_decay = learning_rate_decay,\n",
    "        l1_regularization_strength = l1_regularization_strength, l2_regularization_strength = l2_regularization_strength,\n",
    "        conv2d_prune_amount = 0.2, linear_prune_amount = 0.1,\n",
    "        num_iterations = 21, num_epochs_per_iteration = 20,\n",
    "        model_filename_prefix = model_filename_prefix, model_dir = model_dir,\n",
    "        grouped_pruning = True)\n",
    "\n",
    "\n",
    "# Apply pruned mask to the parameters/weights and remove the masks-\n",
    "remove_parameters(model = pruned_model)\n",
    "\n",
    "_, eval_accuracy = evaluate_model(\n",
    "    model = pruned_model, test_loader = test_loader,\n",
    "    device = device, criterion = None\n",
    ")\n",
    "\n",
    "'''\n",
    "classification_report = create_classification_report(\n",
    "    model = pruned_model, test_loader = test_loader,\n",
    "    device = device)\n",
    "'''\n",
    "\n",
    "num_zeros, num_elements, sparsity = measure_global_sparsity(pruned_model)\n",
    "\n",
    "\n",
    "print(f\"Global sparsity = {sparsity:.3f} & val_accuracy = {eval_accuracy:.3f}\")\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report)\n",
    "# NOTE: classification report is avoided as it's too verbose!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-lesbian",
   "metadata": {
    "id": "ZAw22aywnj-n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "flush-protest",
   "metadata": {
    "id": "wKkt-PB1SXRW"
   },
   "outputs": [],
   "source": [
    "# Remove pruning parameters-\n",
    "final_model = remove_parameters(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "threatened-tragedy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7a24a695-dc89-470e-8d85-5453ecc82deb",
    "outputId": "705d6d7d-893d-485d-cedb-56baf2285671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity = 99.078% & val_accuracy = 92.940%\n"
     ]
    }
   ],
   "source": [
    "# Compute final model's val_accuracy and global sparsity-\n",
    "_, eval_accuracy = evaluate_model(\n",
    "    model = final_model, test_loader = test_loader,\n",
    "    device = device, criterion = None)\n",
    "\n",
    "num_zeros, num_elements, sparsity = measure_global_sparsity(pruned_model)\n",
    "print(f\"Global sparsity = {sparsity * 100:.3f}%\"\n",
    "f\" & val_accuracy = {eval_accuracy * 100:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-birthday",
   "metadata": {
    "id": "niTw6STRPFRV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dietary-thunder",
   "metadata": {
    "id": "RvI-uCRJPKBe"
   },
   "outputs": [],
   "source": [
    "# Save final trained and pruned model for later use-\n",
    "torch.save(final_model.state_dict(), f\"ResNet50_trained_sparsity-{sparsity * 100:.3f}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cooked-stanley",
   "metadata": {
    "id": "7CVnjpFbPq06"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-hepatitis",
   "metadata": {
    "id": "AKB2rtbDREL-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-resort",
   "metadata": {
    "id": "0etCF3nGRE0x"
   },
   "source": [
    "### Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "moved-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and load 'best' weights from before-\n",
    "trained_pruned_model = models.resnet50(pretrained = False)\n",
    "\n",
    "# Compute number of features for defining last linear/dense layer-\n",
    "num_ftrs = trained_pruned_model.fc.in_features\n",
    "\n",
    "# Define last dense layer-\n",
    "trained_pruned_model.fc = nn.Linear(in_features = num_ftrs, out_features = 10)\n",
    "\n",
    "# Change first conv layer of ResNet-50:\n",
    "trained_pruned_model.conv1 = torch.nn.Conv2d(\n",
    "    in_channels = 3, out_channels = 64,\n",
    "    kernel_size = (3, 3), stride = (1, 1),\n",
    "    padding = (1, 1), bias = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vertical-democracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_pruned_model.load_state_dict(torch.load('ResNet50_trained_sparsity-99.078.pth', map_location = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to GPU (if available)-\n",
    "trained_pruned_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cost function and optimizer-\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# It seems that SGD optimizer is better than Adam optimizer for ResNet18 training on CIFAR10-\n",
    "optimizer = torch.optim.SGD(\n",
    "        trained_pruned_model.parameters(), lr = learning_rate,\n",
    "        momentum = 0.9, weight_decay = l2_regularization_strength\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "outdoor-journal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKyL1Z1AQOlq",
    "outputId": "93a7f07a-e2bc-4094-fbe9-bec29391f707"
   },
   "outputs": [],
   "source": [
    "# Compute final model's val_accuracy and global sparsity-\n",
    "eval_loss, eval_accuracy = evaluate_model(\n",
    "    model = trained_pruned_model, test_loader=test_loader,\n",
    "    device = device, criterion = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "informative-chemical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity = 99.078%, val_loss = 0.000 & val_accuracy = 92.940%\n"
     ]
    }
   ],
   "source": [
    "num_zeros, num_elements, sparsity = measure_global_sparsity(\n",
    "    trained_pruned_model, weight = True,\n",
    "    bias = False, conv2d_use_mask = False,\n",
    "    linear_use_mask = False\n",
    ")\n",
    "\n",
    "print(f\"Global sparsity = {sparsity * 100:.3f}%, val_loss = {eval_loss:.3f}\"\n",
    "f\" & val_accuracy = {eval_accuracy * 100:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-heather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-environment",
   "metadata": {
    "id": "39tGyip0QgdY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-apparel",
   "metadata": {
    "id": "CPfhqN7EQggV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "8b1197ed-c2f3-4b17-a458-d5a495055a7c"
   ],
   "name": "ResNet50_Global_Absolute_Magnitude_Pruning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "164f25694e0548c2ab4c689cd739f340": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2099c8dece854e6e819550a228ee3cd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f06268f3268b4bc99258902958afb3e8",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4cc0ee1a167a411684ee8baab0f59236",
      "value": 170498071
     }
    },
    "4cc0ee1a167a411684ee8baab0f59236": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a36dbd2cb3924fecbbadf92c884898f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd4e2bb0a01e42c49833287b4f24d7e4",
      "placeholder": "​",
      "style": "IPY_MODEL_164f25694e0548c2ab4c689cd739f340",
      "value": " 170499072/? [15:58&lt;00:00, 177917.03it/s]"
     }
    },
    "b1cac9f553064d35b254b81d890e52a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd4e2bb0a01e42c49833287b4f24d7e4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f06268f3268b4bc99258902958afb3e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fea7f1d561514a0da92664717b8515c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2099c8dece854e6e819550a228ee3cd7",
       "IPY_MODEL_a36dbd2cb3924fecbbadf92c884898f7"
      ],
      "layout": "IPY_MODEL_b1cac9f553064d35b254b81d890e52a3"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
